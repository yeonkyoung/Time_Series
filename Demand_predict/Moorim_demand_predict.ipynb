{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\USER\\\\Documents\\\\GitHub\\\\Time_Series_models\\\\Demand_predict', 'c:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python39.zip', 'c:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\DLLs', 'c:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib', 'c:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39', '', 'c:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages', 'c:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\Pythonwin', 'C:/Users/USER/Documents/GitHub/Time_Series_models/Demand_predict/', 'C:/Users/USER/Documents/GitHub/Time_Series_models/Demand_predict/']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24412\\872417664.py:4: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n"
     ]
    }
   ],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta\n",
    "import autokeras as ak\n",
    "from kerastuner import HyperModel\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from pickle import dump,load\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "# from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "\n",
    "#만든 모듈을 불러옴\n",
    "import sys\n",
    "from importlib import reload\n",
    "sys.path.append('C:/Users/USER/Documents/GitHub/Time_Series_models/Demand_predict/') \n",
    "print(sys.path)\n",
    "import LSTM_module as tsm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42766 entries, 0 to 42765\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   기준시각         42766 non-null  datetime64[ns]\n",
      " 1   직전 15분 사용전력  42766 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 668.3 KB\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_excel('C:/Users/USER/Desktop/진행중/FEMS/datamart/무림페이퍼_15분사용전력_210401-220630.xlsx')\n",
    "data.columns\n",
    "data=data.drop(['등록시각'],axis=1)\n",
    "data['기준시각']=pd.to_datetime(data['기준시각'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df= 2021-04-01 00:00:00 ~ 2022-05-31 23:45:00 , 39886\n",
      "val_df= 2022-06-01 00:00:00 ~ 2022-06-29 23:45:00 , 2784\n"
     ]
    }
   ],
   "source": [
    "#train_test split\n",
    "def train_test_split(data_t,train_cut_date,val_cut_date): \n",
    "  \n",
    "    df_train = data_t[data_t['기준시각'] < train_cut_date ]\n",
    "    df_val= data_t[(data_t['기준시각'] >= train_cut_date ) & (data_t['기준시각'] < val_cut_date )]\n",
    "    df_test = data_t[(data_t['기준시각'] >= val_cut_date)] \n",
    "    \n",
    "    return (df_train,df_val,df_test) \n",
    "\n",
    "df_train,df_val,df_test=train_test_split(data,'2022-06-01','2022-06-30')\n",
    "print('train_df=',min(df_train['기준시각']),'~',max(df_train['기준시각']),',',len(df_train))\n",
    "print('val_df=',min(df_val['기준시각']),'~',max(df_val['기준시각']),',',len(df_val))\n",
    "# print('test_df=',min(df_test['기준시각']),'~',max(df_test['기준시각']),',',len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dateaframe to tensor\n",
    "nd=np.asarray(df_train['직전 15분 사용전력'])\n",
    "ndd=nd.reshape(len(df_train),)\n",
    "\n",
    "nv=np.asarray(df_val['직전 15분 사용전력'])\n",
    "nvv=nv.reshape(len(df_val),)\n",
    "\n",
    "nt=np.asarray(df_test['직전 15분 사용전력'])\n",
    "ntt=nt.reshape(len(df_test),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39876, 10)\n",
      "(39876,)\n",
      "(2774, 10)\n",
      "(2774,)\n",
      "(86, 10)\n",
      "(86,)\n"
     ]
    }
   ],
   "source": [
    "n_steps = 10\n",
    "(train_x, train_y) = tsm.split_sequence(ndd, n_steps) \n",
    "print(train_x.shape) \n",
    "print(train_y.shape)\n",
    "(val_x, val_y) = tsm.split_sequence(nvv, n_steps) \n",
    "print(val_x.shape) \n",
    "print(val_y.shape)\n",
    "(test_x, test_y) = tsm.split_sequence(ntt, n_steps) \n",
    "print(test_x.shape) \n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39876, 10, 1)\n",
      "(2774, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "n_features = 1\n",
    "train_x = train_x.reshape(train_x.shape[0], n_steps, n_features)\n",
    "val_x = val_x.reshape(val_x.shape[0], n_steps, n_features)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(val_x.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(train,val)\n",
    "# Hyperparameter Setting\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE=100\n",
    "\n",
    "# # Dataset -> Tensor\n",
    "train_univariate = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_univariate = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoArima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=data[data['직전 15분 사용전력']>7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시계열 모델을 위한 tsdata화\n",
    "\n",
    "ts_data=data.set_index('기준시각')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import adfuller   #H0=안정적이지 않음(비정상시계열) / H1:안정적임(정상시계열)\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomposition_plot(ts):\n",
    "    # Apply seasonal_decompose \n",
    "    decomposition = seasonal_decompose(ts)\n",
    "    \n",
    "    # Get trend, seasonality, and residuals\n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    residual = decomposition.resid\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(411)\n",
    "    plt.plot(np.log(ts), label='Original', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(412)\n",
    "    plt.plot(trend, label='Trend', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(413)\n",
    "    plt.plot(seasonal,label='Seasonality', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(414)\n",
    "    plt.plot(residual, label='Residuals', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def stationarity_check(ts):\n",
    "            \n",
    "    # Calculate rolling statistics\n",
    "    roll_mean = ts.rolling(window=8, center=False).mean()\n",
    "    roll_std = ts.rolling(window=8, center=False).std()\n",
    "\n",
    "    # Perform the Dickey Fuller test\n",
    "    dftest = adfuller(ts) \n",
    "    \n",
    "    # Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    orig = plt.plot(ts, color='blue',label='Original')\n",
    "    mean = plt.plot(roll_mean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(roll_std, color='green', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    # Print Dickey-Fuller test results\n",
    "\n",
    "    print('\\nResults of Dickey-Fuller Test: \\n')\n",
    "\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', \n",
    "                                             '#Lags Used', 'Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results of Dickey-Fuller Test: \n",
      "\n",
      "Test Statistic                -1.627340e+01\n",
      "p-value                        3.469746e-29\n",
      "#Lags Used                     1.300000e+01\n",
      "Number of Observations Used    2.290600e+04\n",
      "Critical Value (1%)           -3.430636e+00\n",
      "Critical Value (5%)           -2.861666e+00\n",
      "Critical Value (10%)          -2.566837e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "stationarity_check(ts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import model_selection\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "def TS_holdout(ts,testsize): #\"testsize\"= 예측을 원하는 개월 수(h)\n",
    "    \n",
    "    train, test = model_selection.train_test_split(ts, train_size=len(ts)-testsize)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>직전 15분 사용전력</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기준시각</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-01 00:00:00</th>\n",
       "      <td>7224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01 00:15:00</th>\n",
       "      <td>7274.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01 00:30:00</th>\n",
       "      <td>7442.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01 00:45:00</th>\n",
       "      <td>7392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01 01:00:00</th>\n",
       "      <td>7576.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 06:45:00</th>\n",
       "      <td>7761.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 07:00:00</th>\n",
       "      <td>7812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 07:15:00</th>\n",
       "      <td>7845.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 07:30:00</th>\n",
       "      <td>7996.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 07:45:00</th>\n",
       "      <td>7996.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22890 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     직전 15분 사용전력\n",
       "기준시각                            \n",
       "2021-04-01 00:00:00       7224.0\n",
       "2021-04-01 00:15:00       7274.4\n",
       "2021-04-01 00:30:00       7442.4\n",
       "2021-04-01 00:45:00       7392.0\n",
       "2021-04-01 01:00:00       7576.8\n",
       "...                          ...\n",
       "2022-06-25 06:45:00       7761.6\n",
       "2022-06-25 07:00:00       7812.0\n",
       "2022-06-25 07:15:00       7845.6\n",
       "2022-06-25 07:30:00       7996.8\n",
       "2022-06-25 07:45:00       7996.8\n",
       "\n",
       "[22890 rows x 1 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test=TS_holdout(ts_data,30)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=284760.737, Time=0.22 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=284761.004, Time=0.44 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=284759.913, Time=0.71 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=284758.739, Time=0.14 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=283817.805, Time=3.64 sec\n",
      " ARIMA(2,1,1)(0,0,0)[0] intercept   : AIC=283370.540, Time=6.13 sec\n",
      " ARIMA(2,1,0)(0,0,0)[0] intercept   : AIC=283881.183, Time=0.68 sec\n",
      " ARIMA(3,1,1)(0,0,0)[0] intercept   : AIC=inf, Time=8.44 sec\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=283316.734, Time=6.42 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0] intercept   : AIC=283318.230, Time=2.45 sec\n",
      " ARIMA(3,1,2)(0,0,0)[0] intercept   : AIC=inf, Time=12.10 sec\n",
      " ARIMA(2,1,3)(0,0,0)[0] intercept   : AIC=inf, Time=16.48 sec\n",
      " ARIMA(1,1,3)(0,0,0)[0] intercept   : AIC=283314.311, Time=4.77 sec\n",
      " ARIMA(0,1,3)(0,0,0)[0] intercept   : AIC=283415.353, Time=1.63 sec\n",
      " ARIMA(1,1,4)(0,0,0)[0] intercept   : AIC=inf, Time=10.60 sec\n",
      " ARIMA(0,1,2)(0,0,0)[0] intercept   : AIC=283712.230, Time=0.91 sec\n",
      " ARIMA(0,1,4)(0,0,0)[0] intercept   : AIC=283364.443, Time=1.63 sec\n",
      " ARIMA(2,1,4)(0,0,0)[0] intercept   : AIC=inf, Time=9.10 sec\n",
      " ARIMA(1,1,3)(0,0,0)[0]             : AIC=283312.306, Time=1.97 sec\n",
      " ARIMA(0,1,3)(0,0,0)[0]             : AIC=283413.356, Time=0.72 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0]             : AIC=283316.234, Time=1.06 sec\n",
      " ARIMA(2,1,3)(0,0,0)[0]             : AIC=inf, Time=6.85 sec\n",
      " ARIMA(1,1,4)(0,0,0)[0]             : AIC=inf, Time=6.60 sec\n",
      " ARIMA(0,1,2)(0,0,0)[0]             : AIC=283710.232, Time=0.41 sec\n",
      " ARIMA(0,1,4)(0,0,0)[0]             : AIC=283362.447, Time=0.78 sec\n",
      " ARIMA(2,1,2)(0,0,0)[0]             : AIC=283314.893, Time=1.49 sec\n",
      " ARIMA(2,1,4)(0,0,0)[0]             : AIC=inf, Time=8.62 sec\n",
      "\n",
      "Best model:  ARIMA(1,1,3)(0,0,0)[0]          \n",
      "Total fit time: 115.006 seconds\n"
     ]
    }
   ],
   "source": [
    "from pmdarima.arima import auto_arima\n",
    "model= auto_arima(train, trace=True,suppress_warnings=True, start_p=0, start_q=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>SARIMAX Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>    <td>22890</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>           <td>SARIMAX(1, 1, 3)</td> <th>  Log Likelihood     </th> <td>-141651.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 14 Jul 2022</td> <th>  AIC                </th> <td>283312.306</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:57:52</td>     <th>  BIC                </th> <td>283352.498</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                  <td>0</td>        <th>  HQIC               </th> <td>283325.370</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                     <td> - 22890</td>     <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>opg</td>       <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L1</th>  <td>    0.6283</td> <td>    0.024</td> <td>   26.440</td> <td> 0.000</td> <td>    0.582</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L1</th>  <td>   -0.6568</td> <td>    0.025</td> <td>  -26.395</td> <td> 0.000</td> <td>   -0.706</td> <td>   -0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L2</th>  <td>   -0.2040</td> <td>    0.006</td> <td>  -33.009</td> <td> 0.000</td> <td>   -0.216</td> <td>   -0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L3</th>  <td>    0.0445</td> <td>    0.010</td> <td>    4.303</td> <td> 0.000</td> <td>    0.024</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigma2</th> <td> 1.393e+04</td> <td>   68.348</td> <td>  203.841</td> <td> 0.000</td> <td> 1.38e+04</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Ljung-Box (L1) (Q):</th>     <td>0.01</td> <th>  Jarque-Bera (JB):  </th> <td>28579.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Q):</th>                <td>0.91</td> <th>  Prob(JB):          </th>   <td>0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Heteroskedasticity (H):</th> <td>0.78</td> <th>  Skew:              </th>   <td>-0.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(H) (two-sided):</th>    <td>0.00</td> <th>  Kurtosis:          </th>   <td>8.46</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               SARIMAX Results                                \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                22890\n",
       "Model:               SARIMAX(1, 1, 3)   Log Likelihood             -141651.153\n",
       "Date:                Thu, 14 Jul 2022   AIC                         283312.306\n",
       "Time:                        16:57:52   BIC                         283352.498\n",
       "Sample:                             0   HQIC                        283325.370\n",
       "                              - 22890                                         \n",
       "Covariance Type:                  opg                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "ar.L1          0.6283      0.024     26.440      0.000       0.582       0.675\n",
       "ma.L1         -0.6568      0.025    -26.395      0.000      -0.706      -0.608\n",
       "ma.L2         -0.2040      0.006    -33.009      0.000      -0.216      -0.192\n",
       "ma.L3          0.0445      0.010      4.303      0.000       0.024       0.065\n",
       "sigma2      1.393e+04     68.348    203.841      0.000    1.38e+04    1.41e+04\n",
       "===================================================================================\n",
       "Ljung-Box (L1) (Q):                   0.01   Jarque-Bera (JB):             28579.99\n",
       "Prob(Q):                              0.91   Prob(JB):                         0.00\n",
       "Heteroskedasticity (H):               0.78   Skew:                            -0.17\n",
       "Prob(H) (two-sided):                  0.00   Kurtosis:                         8.46\n",
       "===================================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
       "\"\"\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_predict=30\n",
    "prediction=pd.DataFrame(model.predict(n_periods=w_predict))\n",
    "prediction.columns=['predicted']\n",
    "prediction.index=test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_graph(test,prediction) : #train,\n",
    "    plt.figure(figsize=(30,10))\n",
    "    kws = dict(marker='o')\n",
    "    # plt.plot(train, label='Train', **kws)   \n",
    "    plt.plot(test, label='Test', **kws)   \n",
    "    plt.plot(prediction,label='predicted', **kws)\n",
    "    plt.legend()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>직전 15분 사용전력</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기준시각</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-25 08:00:00</th>\n",
       "      <td>8047.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 08:15:00</th>\n",
       "      <td>8064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 08:30:00</th>\n",
       "      <td>7980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 08:45:00</th>\n",
       "      <td>7744.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 09:00:00</th>\n",
       "      <td>7862.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 09:15:00</th>\n",
       "      <td>7828.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 09:30:00</th>\n",
       "      <td>8064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 09:45:00</th>\n",
       "      <td>8114.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 10:00:00</th>\n",
       "      <td>8080.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 10:15:00</th>\n",
       "      <td>8131.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 10:30:00</th>\n",
       "      <td>8080.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 10:45:00</th>\n",
       "      <td>8030.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 11:00:00</th>\n",
       "      <td>7929.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 11:15:00</th>\n",
       "      <td>7795.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 11:30:00</th>\n",
       "      <td>7744.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 11:45:00</th>\n",
       "      <td>7778.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 12:00:00</th>\n",
       "      <td>7761.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 12:15:00</th>\n",
       "      <td>7728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 12:30:00</th>\n",
       "      <td>7845.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 12:45:00</th>\n",
       "      <td>7778.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 13:00:00</th>\n",
       "      <td>7728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 13:15:00</th>\n",
       "      <td>7711.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 13:30:00</th>\n",
       "      <td>7711.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 13:45:00</th>\n",
       "      <td>7593.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 14:00:00</th>\n",
       "      <td>7677.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 14:15:00</th>\n",
       "      <td>7560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 14:30:00</th>\n",
       "      <td>7560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 14:45:00</th>\n",
       "      <td>7358.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 15:00:00</th>\n",
       "      <td>7291.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 15:15:00</th>\n",
       "      <td>7408.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     직전 15분 사용전력\n",
       "기준시각                            \n",
       "2022-06-25 08:00:00       8047.2\n",
       "2022-06-25 08:15:00       8064.0\n",
       "2022-06-25 08:30:00       7980.0\n",
       "2022-06-25 08:45:00       7744.8\n",
       "2022-06-25 09:00:00       7862.4\n",
       "2022-06-25 09:15:00       7828.8\n",
       "2022-06-25 09:30:00       8064.0\n",
       "2022-06-25 09:45:00       8114.4\n",
       "2022-06-25 10:00:00       8080.8\n",
       "2022-06-25 10:15:00       8131.2\n",
       "2022-06-25 10:30:00       8080.8\n",
       "2022-06-25 10:45:00       8030.4\n",
       "2022-06-25 11:00:00       7929.6\n",
       "2022-06-25 11:15:00       7795.2\n",
       "2022-06-25 11:30:00       7744.8\n",
       "2022-06-25 11:45:00       7778.4\n",
       "2022-06-25 12:00:00       7761.6\n",
       "2022-06-25 12:15:00       7728.0\n",
       "2022-06-25 12:30:00       7845.6\n",
       "2022-06-25 12:45:00       7778.4\n",
       "2022-06-25 13:00:00       7728.0\n",
       "2022-06-25 13:15:00       7711.2\n",
       "2022-06-25 13:30:00       7711.2\n",
       "2022-06-25 13:45:00       7593.6\n",
       "2022-06-25 14:00:00       7677.6\n",
       "2022-06-25 14:15:00       7560.0\n",
       "2022-06-25 14:30:00       7560.0\n",
       "2022-06-25 14:45:00       7358.4\n",
       "2022-06-25 15:00:00       7291.2\n",
       "2022-06-25 15:15:00       7408.8"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기준시각</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-25 08:00:00</th>\n",
       "      <td>7990.840796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 08:15:00</th>\n",
       "      <td>7997.837021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 08:30:00</th>\n",
       "      <td>8000.978441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 08:45:00</th>\n",
       "      <td>8002.952341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 09:00:00</th>\n",
       "      <td>8004.192634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 09:15:00</th>\n",
       "      <td>8004.971967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 09:30:00</th>\n",
       "      <td>8005.461659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 09:45:00</th>\n",
       "      <td>8005.769355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 10:00:00</th>\n",
       "      <td>8005.962695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 10:15:00</th>\n",
       "      <td>8006.084179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 10:30:00</th>\n",
       "      <td>8006.160513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 10:45:00</th>\n",
       "      <td>8006.208478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 11:00:00</th>\n",
       "      <td>8006.238616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 11:15:00</th>\n",
       "      <td>8006.257553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 11:30:00</th>\n",
       "      <td>8006.269452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 11:45:00</th>\n",
       "      <td>8006.276929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 12:00:00</th>\n",
       "      <td>8006.281627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 12:15:00</th>\n",
       "      <td>8006.284579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 12:30:00</th>\n",
       "      <td>8006.286434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 12:45:00</th>\n",
       "      <td>8006.287599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 13:00:00</th>\n",
       "      <td>8006.288332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 13:15:00</th>\n",
       "      <td>8006.288792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 13:30:00</th>\n",
       "      <td>8006.289081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 13:45:00</th>\n",
       "      <td>8006.289263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 14:00:00</th>\n",
       "      <td>8006.289377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 14:15:00</th>\n",
       "      <td>8006.289449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 14:30:00</th>\n",
       "      <td>8006.289494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 14:45:00</th>\n",
       "      <td>8006.289522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 15:00:00</th>\n",
       "      <td>8006.289540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 15:15:00</th>\n",
       "      <td>8006.289551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       predicted\n",
       "기준시각                            \n",
       "2022-06-25 08:00:00  7990.840796\n",
       "2022-06-25 08:15:00  7997.837021\n",
       "2022-06-25 08:30:00  8000.978441\n",
       "2022-06-25 08:45:00  8002.952341\n",
       "2022-06-25 09:00:00  8004.192634\n",
       "2022-06-25 09:15:00  8004.971967\n",
       "2022-06-25 09:30:00  8005.461659\n",
       "2022-06-25 09:45:00  8005.769355\n",
       "2022-06-25 10:00:00  8005.962695\n",
       "2022-06-25 10:15:00  8006.084179\n",
       "2022-06-25 10:30:00  8006.160513\n",
       "2022-06-25 10:45:00  8006.208478\n",
       "2022-06-25 11:00:00  8006.238616\n",
       "2022-06-25 11:15:00  8006.257553\n",
       "2022-06-25 11:30:00  8006.269452\n",
       "2022-06-25 11:45:00  8006.276929\n",
       "2022-06-25 12:00:00  8006.281627\n",
       "2022-06-25 12:15:00  8006.284579\n",
       "2022-06-25 12:30:00  8006.286434\n",
       "2022-06-25 12:45:00  8006.287599\n",
       "2022-06-25 13:00:00  8006.288332\n",
       "2022-06-25 13:15:00  8006.288792\n",
       "2022-06-25 13:30:00  8006.289081\n",
       "2022-06-25 13:45:00  8006.289263\n",
       "2022-06-25 14:00:00  8006.289377\n",
       "2022-06-25 14:15:00  8006.289449\n",
       "2022-06-25 14:30:00  8006.289494\n",
       "2022-06-25 14:45:00  8006.289522\n",
       "2022-06-25 15:00:00  8006.289540\n",
       "2022-06-25 15:15:00  8006.289551"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph\n",
    "predict_graph(test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\time_series_forecaster\\oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\time_series_forecaster\\oracle.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from .\\time_series_forecaster\\tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from .\\time_series_forecaster\\tuner0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1247/1247 [==============================] - 11s 7ms/step - loss: 48796276.0000 - mean_squared_error: 48796276.0000 - val_loss: 47664604.0000 - val_mean_squared_error: 47664604.0000\n",
      "Epoch 2/10\n",
      "1247/1247 [==============================] - 7s 6ms/step - loss: 48416108.0000 - mean_squared_error: 48416108.0000 - val_loss: 47314188.0000 - val_mean_squared_error: 47314188.0000\n",
      "Epoch 3/10\n",
      "1247/1247 [==============================] - 7s 6ms/step - loss: 48068628.0000 - mean_squared_error: 48068628.0000 - val_loss: 46970412.0000 - val_mean_squared_error: 46970412.0000\n",
      "Epoch 4/10\n",
      "1247/1247 [==============================] - 7s 6ms/step - loss: 47721208.0000 - mean_squared_error: 47721208.0000 - val_loss: 46628528.0000 - val_mean_squared_error: 46628528.0000\n",
      "Epoch 5/10\n",
      "1247/1247 [==============================] - 7s 6ms/step - loss: 47379200.0000 - mean_squared_error: 47379200.0000 - val_loss: 46288756.0000 - val_mean_squared_error: 46288756.0000\n",
      "Epoch 6/10\n",
      "1247/1247 [==============================] - 7s 6ms/step - loss: 47036004.0000 - mean_squared_error: 47036004.0000 - val_loss: 45950136.0000 - val_mean_squared_error: 45950136.0000\n",
      "Epoch 7/10\n",
      "1247/1247 [==============================] - 7s 6ms/step - loss: 46697236.0000 - mean_squared_error: 46697236.0000 - val_loss: 45613108.0000 - val_mean_squared_error: 45613108.0000\n",
      "Epoch 8/10\n",
      "1247/1247 [==============================] - 8s 6ms/step - loss: 46359392.0000 - mean_squared_error: 46359392.0000 - val_loss: 45277348.0000 - val_mean_squared_error: 45277348.0000\n",
      "Epoch 9/10\n",
      "1247/1247 [==============================] - 8s 6ms/step - loss: 46017884.0000 - mean_squared_error: 46017884.0000 - val_loss: 44942696.0000 - val_mean_squared_error: 44942696.0000\n",
      "Epoch 10/10\n",
      "1247/1247 [==============================] - 7s 6ms/step - loss: 45683684.0000 - mean_squared_error: 45683684.0000 - val_loss: 44609688.0000 - val_mean_squared_error: 44609688.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\time_series_forecaster\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\time_series_forecaster\\best_model\\assets\n"
     ]
    }
   ],
   "source": [
    "predict_from = 30\n",
    "predict_until = 10\n",
    "lookback = 3\n",
    "clf = ak.TimeseriesForecaster(\n",
    "    lookback=lookback,\n",
    "    predict_from=predict_from,\n",
    "    predict_until=predict_until,\n",
    "    max_trials=1,\n",
    "    objective=\"val_loss\",\n",
    ")\n",
    "# Train the TimeSeriesForecaster with train data\n",
    "model=clf.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    validation_data=(val_x, val_y),\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247/1247 [==============================] - 7s 5ms/step\n",
      "1247/1247 [==============================] - 7s 5ms/step\n",
      "(0, 1)\n",
      "3/3 [==============================] - 1s 12ms/step - loss: 32334866.0000 - mean_squared_error: 32334866.0000\n",
      "[32334866.0, 32334866.0]\n"
     ]
    }
   ],
   "source": [
    "# Predict with the best model(includes original training data).\n",
    "predictions = clf.predict(train_x)\n",
    "print(predictions.shape)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet(pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['기준시각','직전 15분 사용전력']]\n",
    "data['기준시각']=pd.to_datetime(data['기준시각'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = \"lstm_model_checkpoint_try4.h5\"\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0, patience=100, mode='auto')# mode=auto loss면 최저값100번정도 반복되면 정지, acc면 최고값이 100번정도 반복되면 정지\n",
    "\n",
    "modelckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Simple LSTM Model\n",
    "simple_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(10, activation = 'relu', input_shape=(n_steps,1),return_sequences=True),#\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(20, activation = 'relu', input_shape=(n_steps,1),return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(10, activation = 'relu', input_shape=(n_steps,1)), \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(5),   \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mse',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 41663796.0000 - mse: 41663796.0000\n",
      "Epoch 1: loss improved from inf to 41495100.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 3s 10ms/step - loss: 41495100.0000 - mse: 41495100.0000 - val_loss: 12922754.0000 - val_mse: 12922754.0000\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 17689754.0000 - mse: 17689754.0000\n",
      "Epoch 2: loss improved from 41495100.00000 to 17689754.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 17689754.0000 - mse: 17689754.0000 - val_loss: 3362504.2500 - val_mse: 3362504.2500\n",
      "Epoch 3/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 14472637.0000 - mse: 14472637.0000\n",
      "Epoch 3: loss improved from 17689754.00000 to 14281874.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 14281874.0000 - mse: 14281874.0000 - val_loss: 5471325.0000 - val_mse: 5471325.0000\n",
      "Epoch 4/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 12132000.0000 - mse: 12132000.0000\n",
      "Epoch 4: loss improved from 14281874.00000 to 12024091.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 12024091.0000 - mse: 12024091.0000 - val_loss: 10988950.0000 - val_mse: 10988950.0000\n",
      "Epoch 5/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 10949460.0000 - mse: 10949460.0000\n",
      "Epoch 5: loss improved from 12024091.00000 to 11001619.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 11001619.0000 - mse: 11001619.0000 - val_loss: 11056953.0000 - val_mse: 11056953.0000\n",
      "Epoch 6/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 10038595.0000 - mse: 10038595.0000\n",
      "Epoch 6: loss improved from 11001619.00000 to 10450575.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 10450575.0000 - mse: 10450575.0000 - val_loss: 7975081.0000 - val_mse: 7975081.0000\n",
      "Epoch 7/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7495221.5000 - mse: 7495221.5000\n",
      "Epoch 7: loss improved from 10450575.00000 to 7555163.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 7555163.0000 - mse: 7555163.0000 - val_loss: 9111950.0000 - val_mse: 9111950.0000\n",
      "Epoch 8/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 8616757.0000 - mse: 8616757.0000\n",
      "Epoch 8: loss did not improve from 7555163.00000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 8411247.0000 - mse: 8411247.0000 - val_loss: 13104516.0000 - val_mse: 13104516.0000\n",
      "Epoch 9/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 8372189.5000 - mse: 8372189.5000\n",
      "Epoch 9: loss did not improve from 7555163.00000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 8370246.0000 - mse: 8370246.0000 - val_loss: 16736234.0000 - val_mse: 16736234.0000\n",
      "Epoch 10/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 8415207.0000 - mse: 8415207.0000\n",
      "Epoch 10: loss did not improve from 7555163.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8529891.0000 - mse: 8529891.0000 - val_loss: 13200635.0000 - val_mse: 13200635.0000\n",
      "Epoch 11/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 8428894.0000 - mse: 8428894.0000\n",
      "Epoch 11: loss did not improve from 7555163.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8423428.0000 - mse: 8423428.0000 - val_loss: 14578826.0000 - val_mse: 14578826.0000\n",
      "Epoch 12/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 7736088.0000 - mse: 7736088.0000\n",
      "Epoch 12: loss did not improve from 7555163.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7638177.5000 - mse: 7638177.5000 - val_loss: 14811670.0000 - val_mse: 14811670.0000\n",
      "Epoch 13/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7783109.5000 - mse: 7783109.5000\n",
      "Epoch 13: loss did not improve from 7555163.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7753292.0000 - mse: 7753292.0000 - val_loss: 16527201.0000 - val_mse: 16527201.0000\n",
      "Epoch 14/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 8035363.0000 - mse: 8035363.0000\n",
      "Epoch 14: loss did not improve from 7555163.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8044248.5000 - mse: 8044248.5000 - val_loss: 14726104.0000 - val_mse: 14726104.0000\n",
      "Epoch 15/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 8222280.5000 - mse: 8222280.5000\n",
      "Epoch 15: loss did not improve from 7555163.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 8250510.0000 - mse: 8250510.0000 - val_loss: 15440638.0000 - val_mse: 15440638.0000\n",
      "Epoch 16/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7701744.0000 - mse: 7701744.0000\n",
      "Epoch 16: loss did not improve from 7555163.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7774773.0000 - mse: 7774773.0000 - val_loss: 14275962.0000 - val_mse: 14275962.0000\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 6950781.5000 - mse: 6950781.5000\n",
      "Epoch 17: loss improved from 7555163.00000 to 6950781.50000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 6950781.5000 - mse: 6950781.5000 - val_loss: 13807466.0000 - val_mse: 13807466.0000\n",
      "Epoch 18/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7628744.0000 - mse: 7628744.0000\n",
      "Epoch 18: loss did not improve from 6950781.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7604939.5000 - mse: 7604939.5000 - val_loss: 14628658.0000 - val_mse: 14628658.0000\n",
      "Epoch 19/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 6839383.0000 - mse: 6839383.0000\n",
      "Epoch 19: loss did not improve from 6950781.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7029078.5000 - mse: 7029078.5000 - val_loss: 31974620.0000 - val_mse: 31974620.0000\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 6215905.5000 - mse: 6215905.5000\n",
      "Epoch 20: loss improved from 6950781.50000 to 6215905.50000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 6215905.5000 - mse: 6215905.5000 - val_loss: 20519564.0000 - val_mse: 20519564.0000\n",
      "Epoch 21/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 6220216.0000 - mse: 6220216.0000\n",
      "Epoch 21: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 6234050.0000 - mse: 6234050.0000 - val_loss: 16638837.0000 - val_mse: 16638837.0000\n",
      "Epoch 22/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 7099545.0000 - mse: 7099545.0000\n",
      "Epoch 22: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7097682.5000 - mse: 7097682.5000 - val_loss: 20870244.0000 - val_mse: 20870244.0000\n",
      "Epoch 23/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 7068056.5000 - mse: 7068056.5000\n",
      "Epoch 23: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6985011.0000 - mse: 6985011.0000 - val_loss: 16953488.0000 - val_mse: 16953488.0000\n",
      "Epoch 24/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7227032.0000 - mse: 7227032.0000\n",
      "Epoch 24: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7201823.5000 - mse: 7201823.5000 - val_loss: 17172154.0000 - val_mse: 17172154.0000\n",
      "Epoch 25/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 7012888.0000 - mse: 7012888.0000\n",
      "Epoch 25: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7060975.0000 - mse: 7060975.0000 - val_loss: 16685422.0000 - val_mse: 16685422.0000\n",
      "Epoch 26/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 6754053.0000 - mse: 6754053.0000\n",
      "Epoch 26: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6735850.0000 - mse: 6735850.0000 - val_loss: 18818354.0000 - val_mse: 18818354.0000\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 7766479.5000 - mse: 7766479.5000\n",
      "Epoch 27: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7766479.5000 - mse: 7766479.5000 - val_loss: 19329244.0000 - val_mse: 19329244.0000\n",
      "Epoch 28/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7279768.0000 - mse: 7279768.0000\n",
      "Epoch 28: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7355809.5000 - mse: 7355809.5000 - val_loss: 17911666.0000 - val_mse: 17911666.0000\n",
      "Epoch 29/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 7046745.5000 - mse: 7046745.5000\n",
      "Epoch 29: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6921748.5000 - mse: 6921748.5000 - val_loss: 17509384.0000 - val_mse: 17509384.0000\n",
      "Epoch 30/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7101232.0000 - mse: 7101232.0000\n",
      "Epoch 30: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7164538.0000 - mse: 7164538.0000 - val_loss: 17471100.0000 - val_mse: 17471100.0000\n",
      "Epoch 31/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 6712651.0000 - mse: 6712651.0000\n",
      "Epoch 31: loss did not improve from 6215905.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6610308.0000 - mse: 6610308.0000 - val_loss: 17181584.0000 - val_mse: 17181584.0000\n",
      "Epoch 32/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 4732652.0000 - mse: 4732652.0000\n",
      "Epoch 32: loss improved from 6215905.50000 to 4745916.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4745916.0000 - mse: 4745916.0000 - val_loss: 16809632.0000 - val_mse: 16809632.0000\n",
      "Epoch 33/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 6097789.5000 - mse: 6097789.5000\n",
      "Epoch 33: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6075056.0000 - mse: 6075056.0000 - val_loss: 17299468.0000 - val_mse: 17299468.0000\n",
      "Epoch 34/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 6172584.0000 - mse: 6172584.0000\n",
      "Epoch 34: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6104954.0000 - mse: 6104954.0000 - val_loss: 16586806.0000 - val_mse: 16586806.0000\n",
      "Epoch 35/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 6744846.5000 - mse: 6744846.5000\n",
      "Epoch 35: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6703337.0000 - mse: 6703337.0000 - val_loss: 16626336.0000 - val_mse: 16626336.0000\n",
      "Epoch 36/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 6413690.0000 - mse: 6413690.0000\n",
      "Epoch 36: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6409449.0000 - mse: 6409449.0000 - val_loss: 17081100.0000 - val_mse: 17081100.0000\n",
      "Epoch 37/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 6178456.0000 - mse: 6178456.0000\n",
      "Epoch 37: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6187321.5000 - mse: 6187321.5000 - val_loss: 15498330.0000 - val_mse: 15498330.0000\n",
      "Epoch 38/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 6381515.5000 - mse: 6381515.5000\n",
      "Epoch 38: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6468835.5000 - mse: 6468835.5000 - val_loss: 16330091.0000 - val_mse: 16330091.0000\n",
      "Epoch 39/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 7213117.5000 - mse: 7213117.5000\n",
      "Epoch 39: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7225977.5000 - mse: 7225977.5000 - val_loss: 16663796.0000 - val_mse: 16663796.0000\n",
      "Epoch 40/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7407504.0000 - mse: 7407504.0000\n",
      "Epoch 40: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7318095.5000 - mse: 7318095.5000 - val_loss: 17921140.0000 - val_mse: 17921140.0000\n",
      "Epoch 41/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7073034.0000 - mse: 7073034.0000\n",
      "Epoch 41: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7032285.5000 - mse: 7032285.5000 - val_loss: 17102806.0000 - val_mse: 17102806.0000\n",
      "Epoch 42/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 6479293.5000 - mse: 6479293.5000\n",
      "Epoch 42: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6503291.5000 - mse: 6503291.5000 - val_loss: 17319578.0000 - val_mse: 17319578.0000\n",
      "Epoch 43/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 7149090.5000 - mse: 7149090.5000\n",
      "Epoch 43: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7199534.5000 - mse: 7199534.5000 - val_loss: 19588082.0000 - val_mse: 19588082.0000\n",
      "Epoch 44/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 6114035.0000 - mse: 6114035.0000\n",
      "Epoch 44: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6108340.5000 - mse: 6108340.5000 - val_loss: 17895080.0000 - val_mse: 17895080.0000\n",
      "Epoch 45/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 5668901.0000 - mse: 5668901.0000\n",
      "Epoch 45: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5553818.0000 - mse: 5553818.0000 - val_loss: 18479018.0000 - val_mse: 18479018.0000\n",
      "Epoch 46/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 6028709.0000 - mse: 6028709.0000\n",
      "Epoch 46: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6000530.5000 - mse: 6000530.5000 - val_loss: 17757200.0000 - val_mse: 17757200.0000\n",
      "Epoch 47/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 6174133.5000 - mse: 6174133.5000\n",
      "Epoch 47: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6192914.0000 - mse: 6192914.0000 - val_loss: 18628932.0000 - val_mse: 18628932.0000\n",
      "Epoch 48/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 6419153.0000 - mse: 6419153.0000\n",
      "Epoch 48: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6441331.0000 - mse: 6441331.0000 - val_loss: 17742002.0000 - val_mse: 17742002.0000\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 6488682.0000 - mse: 6488682.0000\n",
      "Epoch 49: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6488682.0000 - mse: 6488682.0000 - val_loss: 19130246.0000 - val_mse: 19130246.0000\n",
      "Epoch 50/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 6375812.0000 - mse: 6375812.0000\n",
      "Epoch 50: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6305254.0000 - mse: 6305254.0000 - val_loss: 17371272.0000 - val_mse: 17371272.0000\n",
      "Epoch 51/1000\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 6859582.5000 - mse: 6859582.5000\n",
      "Epoch 51: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 6842034.0000 - mse: 6842034.0000 - val_loss: 19428994.0000 - val_mse: 19428994.0000\n",
      "Epoch 52/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 7219141.0000 - mse: 7219141.0000\n",
      "Epoch 52: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7197430.5000 - mse: 7197430.5000 - val_loss: 20616276.0000 - val_mse: 20616276.0000\n",
      "Epoch 53/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 6587772.0000 - mse: 6587772.0000\n",
      "Epoch 53: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6626912.5000 - mse: 6626912.5000 - val_loss: 17640548.0000 - val_mse: 17640548.0000\n",
      "Epoch 54/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 5544022.0000 - mse: 5544022.0000\n",
      "Epoch 54: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5539391.5000 - mse: 5539391.5000 - val_loss: 15468519.0000 - val_mse: 15468519.0000\n",
      "Epoch 55/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 5892904.0000 - mse: 5892904.0000\n",
      "Epoch 55: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5875292.0000 - mse: 5875292.0000 - val_loss: 16571619.0000 - val_mse: 16571619.0000\n",
      "Epoch 56/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 5308816.0000 - mse: 5308816.0000\n",
      "Epoch 56: loss did not improve from 4745916.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5169127.5000 - mse: 5169127.5000 - val_loss: 12552692.0000 - val_mse: 12552692.0000\n",
      "Epoch 57/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 4214265.0000 - mse: 4214265.0000\n",
      "Epoch 57: loss improved from 4745916.00000 to 4194588.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4194588.0000 - mse: 4194588.0000 - val_loss: 15507258.0000 - val_mse: 15507258.0000\n",
      "Epoch 58/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 4604843.5000 - mse: 4604843.5000\n",
      "Epoch 58: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4615638.5000 - mse: 4615638.5000 - val_loss: 14612948.0000 - val_mse: 14612948.0000\n",
      "Epoch 59/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 5005635.0000 - mse: 5005635.0000\n",
      "Epoch 59: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5033936.0000 - mse: 5033936.0000 - val_loss: 14471970.0000 - val_mse: 14471970.0000\n",
      "Epoch 60/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 5072501.0000 - mse: 5072501.0000\n",
      "Epoch 60: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4990328.0000 - mse: 4990328.0000 - val_loss: 16398870.0000 - val_mse: 16398870.0000\n",
      "Epoch 61/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 4984562.5000 - mse: 4984562.5000\n",
      "Epoch 61: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5046568.0000 - mse: 5046568.0000 - val_loss: 14359997.0000 - val_mse: 14359997.0000\n",
      "Epoch 62/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 4829345.0000 - mse: 4829345.0000\n",
      "Epoch 62: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4847479.5000 - mse: 4847479.5000 - val_loss: 13898529.0000 - val_mse: 13898529.0000\n",
      "Epoch 63/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 4960358.0000 - mse: 4960358.0000\n",
      "Epoch 63: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4991297.0000 - mse: 4991297.0000 - val_loss: 14306397.0000 - val_mse: 14306397.0000\n",
      "Epoch 64/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 5502330.0000 - mse: 5502330.0000\n",
      "Epoch 64: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5540785.5000 - mse: 5540785.5000 - val_loss: 15364030.0000 - val_mse: 15364030.0000\n",
      "Epoch 65/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 5222358.0000 - mse: 5222358.0000\n",
      "Epoch 65: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5233592.0000 - mse: 5233592.0000 - val_loss: 15416579.0000 - val_mse: 15416579.0000\n",
      "Epoch 66/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 4878319.5000 - mse: 4878319.5000\n",
      "Epoch 66: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4881140.0000 - mse: 4881140.0000 - val_loss: 15304682.0000 - val_mse: 15304682.0000\n",
      "Epoch 67/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 4757290.5000 - mse: 4757290.5000\n",
      "Epoch 67: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4756052.5000 - mse: 4756052.5000 - val_loss: 16414822.0000 - val_mse: 16414822.0000\n",
      "Epoch 68/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 5620269.5000 - mse: 5620269.5000\n",
      "Epoch 68: loss did not improve from 4194588.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5597671.0000 - mse: 5597671.0000 - val_loss: 15023904.0000 - val_mse: 15023904.0000\n",
      "Epoch 69/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 3971234.0000 - mse: 3971234.0000\n",
      "Epoch 69: loss improved from 4194588.00000 to 3924779.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3924779.0000 - mse: 3924779.0000 - val_loss: 14834086.0000 - val_mse: 14834086.0000\n",
      "Epoch 70/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 3943795.5000 - mse: 3943795.5000\n",
      "Epoch 70: loss did not improve from 3924779.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 3932665.2500 - mse: 3932665.2500 - val_loss: 14746808.0000 - val_mse: 14746808.0000\n",
      "Epoch 71/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 4419123.5000 - mse: 4419123.5000\n",
      "Epoch 71: loss did not improve from 3924779.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4422085.0000 - mse: 4422085.0000 - val_loss: 15068276.0000 - val_mse: 15068276.0000\n",
      "Epoch 72/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 4611240.0000 - mse: 4611240.0000\n",
      "Epoch 72: loss did not improve from 3924779.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4584224.5000 - mse: 4584224.5000 - val_loss: 14101782.0000 - val_mse: 14101782.0000\n",
      "Epoch 73/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 4422967.5000 - mse: 4422967.5000\n",
      "Epoch 73: loss did not improve from 3924779.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4439541.0000 - mse: 4439541.0000 - val_loss: 14447996.0000 - val_mse: 14447996.0000\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 4868202.0000 - mse: 4868202.0000\n",
      "Epoch 74: loss did not improve from 3924779.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4868202.0000 - mse: 4868202.0000 - val_loss: 12103466.0000 - val_mse: 12103466.0000\n",
      "Epoch 75/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 4806752.5000 - mse: 4806752.5000\n",
      "Epoch 75: loss did not improve from 3924779.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4837151.5000 - mse: 4837151.5000 - val_loss: 13889028.0000 - val_mse: 13889028.0000\n",
      "Epoch 76/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 4963989.0000 - mse: 4963989.0000\n",
      "Epoch 76: loss did not improve from 3924779.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4980869.5000 - mse: 4980869.5000 - val_loss: 15461645.0000 - val_mse: 15461645.0000\n",
      "Epoch 77/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 5000426.0000 - mse: 5000426.0000\n",
      "Epoch 77: loss did not improve from 3924779.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4931994.0000 - mse: 4931994.0000 - val_loss: 15212921.0000 - val_mse: 15212921.0000\n",
      "Epoch 78/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 4729738.0000 - mse: 4729738.0000\n",
      "Epoch 78: loss did not improve from 3924779.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4712733.0000 - mse: 4712733.0000 - val_loss: 13482902.0000 - val_mse: 13482902.0000\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 3905052.2500 - mse: 3905052.2500\n",
      "Epoch 79: loss improved from 3924779.00000 to 3905052.25000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3905052.2500 - mse: 3905052.2500 - val_loss: 14869457.0000 - val_mse: 14869457.0000\n",
      "Epoch 80/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 4826973.0000 - mse: 4826973.0000\n",
      "Epoch 80: loss did not improve from 3905052.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4867064.5000 - mse: 4867064.5000 - val_loss: 15392936.0000 - val_mse: 15392936.0000\n",
      "Epoch 81/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 4263085.5000 - mse: 4263085.5000\n",
      "Epoch 81: loss did not improve from 3905052.25000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 4174322.2500 - mse: 4174322.2500 - val_loss: 16143931.0000 - val_mse: 16143931.0000\n",
      "Epoch 82/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 3596520.0000 - mse: 3596520.0000\n",
      "Epoch 82: loss improved from 3905052.25000 to 3588295.25000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3588295.2500 - mse: 3588295.2500 - val_loss: 14679169.0000 - val_mse: 14679169.0000\n",
      "Epoch 83/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 4070280.2500 - mse: 4070280.2500\n",
      "Epoch 83: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4068326.5000 - mse: 4068326.5000 - val_loss: 15397441.0000 - val_mse: 15397441.0000\n",
      "Epoch 84/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 4218405.0000 - mse: 4218405.0000\n",
      "Epoch 84: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4259572.5000 - mse: 4259572.5000 - val_loss: 13943720.0000 - val_mse: 13943720.0000\n",
      "Epoch 85/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 4123829.7500 - mse: 4123829.7500\n",
      "Epoch 85: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4148951.0000 - mse: 4148951.0000 - val_loss: 14375430.0000 - val_mse: 14375430.0000\n",
      "Epoch 86/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 4126074.0000 - mse: 4126074.0000\n",
      "Epoch 86: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4098950.0000 - mse: 4098950.0000 - val_loss: 15076724.0000 - val_mse: 15076724.0000\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 4057995.2500 - mse: 4057995.2500\n",
      "Epoch 87: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4057995.2500 - mse: 4057995.2500 - val_loss: 15648898.0000 - val_mse: 15648898.0000\n",
      "Epoch 88/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 4216603.5000 - mse: 4216603.5000\n",
      "Epoch 88: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4241173.5000 - mse: 4241173.5000 - val_loss: 15705366.0000 - val_mse: 15705366.0000\n",
      "Epoch 89/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 4281769.0000 - mse: 4281769.0000\n",
      "Epoch 89: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4257482.5000 - mse: 4257482.5000 - val_loss: 15775116.0000 - val_mse: 15775116.0000\n",
      "Epoch 90/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 4120949.2500 - mse: 4120949.2500\n",
      "Epoch 90: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4116106.5000 - mse: 4116106.5000 - val_loss: 16258582.0000 - val_mse: 16258582.0000\n",
      "Epoch 91/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 4172536.2500 - mse: 4172536.2500\n",
      "Epoch 91: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4193526.7500 - mse: 4193526.7500 - val_loss: 16299756.0000 - val_mse: 16299756.0000\n",
      "Epoch 92/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3839497.2500 - mse: 3839497.2500\n",
      "Epoch 92: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3835752.2500 - mse: 3835752.2500 - val_loss: 16216476.0000 - val_mse: 16216476.0000\n",
      "Epoch 93/1000\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 4568541.0000 - mse: 4568541.0000\n",
      "Epoch 93: loss did not improve from 3588295.25000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4456455.5000 - mse: 4456455.5000 - val_loss: 19599674.0000 - val_mse: 19599674.0000\n",
      "Epoch 94/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3118301.5000 - mse: 3118301.5000\n",
      "Epoch 94: loss improved from 3588295.25000 to 3094558.75000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3094558.7500 - mse: 3094558.7500 - val_loss: 19311364.0000 - val_mse: 19311364.0000\n",
      "Epoch 95/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 3461702.2500 - mse: 3461702.2500\n",
      "Epoch 95: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3477875.0000 - mse: 3477875.0000 - val_loss: 17285370.0000 - val_mse: 17285370.0000\n",
      "Epoch 96/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 3397426.7500 - mse: 3397426.7500\n",
      "Epoch 96: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3402541.7500 - mse: 3402541.7500 - val_loss: 15833193.0000 - val_mse: 15833193.0000\n",
      "Epoch 97/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 3548670.2500 - mse: 3548670.2500\n",
      "Epoch 97: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3527767.7500 - mse: 3527767.7500 - val_loss: 16424711.0000 - val_mse: 16424711.0000\n",
      "Epoch 98/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 3807524.2500 - mse: 3807524.2500\n",
      "Epoch 98: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3769244.2500 - mse: 3769244.2500 - val_loss: 15057955.0000 - val_mse: 15057955.0000\n",
      "Epoch 99/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 3655448.7500 - mse: 3655448.7500\n",
      "Epoch 99: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3677735.2500 - mse: 3677735.2500 - val_loss: 14866750.0000 - val_mse: 14866750.0000\n",
      "Epoch 100/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 3656831.2500 - mse: 3656831.2500\n",
      "Epoch 100: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3740395.7500 - mse: 3740395.7500 - val_loss: 15946590.0000 - val_mse: 15946590.0000\n",
      "Epoch 101/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 4016896.7500 - mse: 4016896.7500\n",
      "Epoch 101: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4032252.5000 - mse: 4032252.5000 - val_loss: 18098528.0000 - val_mse: 18098528.0000\n",
      "Epoch 102/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 3991925.5000 - mse: 3991925.5000\n",
      "Epoch 102: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4023485.7500 - mse: 4023485.7500 - val_loss: 8742558.0000 - val_mse: 8742558.0000\n",
      "Epoch 103/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 3830629.2500 - mse: 3830629.2500\n",
      "Epoch 103: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3807773.5000 - mse: 3807773.5000 - val_loss: 16609178.0000 - val_mse: 16609178.0000\n",
      "Epoch 104/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 3383166.7500 - mse: 3383166.7500\n",
      "Epoch 104: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3376001.2500 - mse: 3376001.2500 - val_loss: 17213004.0000 - val_mse: 17213004.0000\n",
      "Epoch 105/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 3848559.7500 - mse: 3848559.7500\n",
      "Epoch 105: loss did not improve from 3094558.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3854871.0000 - mse: 3854871.0000 - val_loss: 14650845.0000 - val_mse: 14650845.0000\n",
      "Epoch 106/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2793789.5000 - mse: 2793789.5000\n",
      "Epoch 106: loss improved from 3094558.75000 to 2791666.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2791666.0000 - mse: 2791666.0000 - val_loss: 14687865.0000 - val_mse: 14687865.0000\n",
      "Epoch 107/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2494366.7500 - mse: 2494366.7500\n",
      "Epoch 107: loss improved from 2791666.00000 to 2522865.50000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2522865.5000 - mse: 2522865.5000 - val_loss: 12627266.0000 - val_mse: 12627266.0000\n",
      "Epoch 108/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2613557.0000 - mse: 2613557.0000\n",
      "Epoch 108: loss did not improve from 2522865.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2611942.5000 - mse: 2611942.5000 - val_loss: 13274655.0000 - val_mse: 13274655.0000\n",
      "Epoch 109/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2732577.7500 - mse: 2732577.7500\n",
      "Epoch 109: loss did not improve from 2522865.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2702930.0000 - mse: 2702930.0000 - val_loss: 12310399.0000 - val_mse: 12310399.0000\n",
      "Epoch 110/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 2801342.7500 - mse: 2801342.7500\n",
      "Epoch 110: loss did not improve from 2522865.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2835480.7500 - mse: 2835480.7500 - val_loss: 11830676.0000 - val_mse: 11830676.0000\n",
      "Epoch 111/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2624281.7500 - mse: 2624281.7500\n",
      "Epoch 111: loss did not improve from 2522865.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2650995.0000 - mse: 2650995.0000 - val_loss: 12526055.0000 - val_mse: 12526055.0000\n",
      "Epoch 112/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2900400.2500 - mse: 2900400.2500\n",
      "Epoch 112: loss did not improve from 2522865.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2908278.0000 - mse: 2908278.0000 - val_loss: 12156010.0000 - val_mse: 12156010.0000\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2736650.7500 - mse: 2736650.7500\n",
      "Epoch 113: loss did not improve from 2522865.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2736650.7500 - mse: 2736650.7500 - val_loss: 13635779.0000 - val_mse: 13635779.0000\n",
      "Epoch 114/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 3154100.0000 - mse: 3154100.0000\n",
      "Epoch 114: loss did not improve from 2522865.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 3109095.2500 - mse: 3109095.2500 - val_loss: 11595556.0000 - val_mse: 11595556.0000\n",
      "Epoch 115/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2863580.7500 - mse: 2863580.7500\n",
      "Epoch 115: loss did not improve from 2522865.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2839494.5000 - mse: 2839494.5000 - val_loss: 13356651.0000 - val_mse: 13356651.0000\n",
      "Epoch 116/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2902373.0000 - mse: 2902373.0000\n",
      "Epoch 116: loss did not improve from 2522865.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2903814.0000 - mse: 2903814.0000 - val_loss: 11101035.0000 - val_mse: 11101035.0000\n",
      "Epoch 117/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2456719.2500 - mse: 2456719.2500\n",
      "Epoch 117: loss improved from 2522865.50000 to 2488114.25000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2488114.2500 - mse: 2488114.2500 - val_loss: 11694734.0000 - val_mse: 11694734.0000\n",
      "Epoch 118/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2771536.7500 - mse: 2771536.7500\n",
      "Epoch 118: loss did not improve from 2488114.25000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2773689.5000 - mse: 2773689.5000 - val_loss: 11635392.0000 - val_mse: 11635392.0000\n",
      "Epoch 119/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2202687.7500 - mse: 2202687.7500\n",
      "Epoch 119: loss improved from 2488114.25000 to 2181332.50000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2181332.5000 - mse: 2181332.5000 - val_loss: 11719248.0000 - val_mse: 11719248.0000\n",
      "Epoch 120/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2482295.2500 - mse: 2482295.2500\n",
      "Epoch 120: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2464718.0000 - mse: 2464718.0000 - val_loss: 13654796.0000 - val_mse: 13654796.0000\n",
      "Epoch 121/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2446575.7500 - mse: 2446575.7500\n",
      "Epoch 121: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2466547.2500 - mse: 2466547.2500 - val_loss: 12441515.0000 - val_mse: 12441515.0000\n",
      "Epoch 122/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2721421.5000 - mse: 2721421.5000\n",
      "Epoch 122: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2724892.5000 - mse: 2724892.5000 - val_loss: 11707242.0000 - val_mse: 11707242.0000\n",
      "Epoch 123/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2649216.5000 - mse: 2649216.5000\n",
      "Epoch 123: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2637448.5000 - mse: 2637448.5000 - val_loss: 11787992.0000 - val_mse: 11787992.0000\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2585969.7500 - mse: 2585969.7500\n",
      "Epoch 124: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2585969.7500 - mse: 2585969.7500 - val_loss: 11990502.0000 - val_mse: 11990502.0000\n",
      "Epoch 125/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 2538413.0000 - mse: 2538413.0000\n",
      "Epoch 125: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2573864.7500 - mse: 2573864.7500 - val_loss: 11910089.0000 - val_mse: 11910089.0000\n",
      "Epoch 126/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 2729200.7500 - mse: 2729200.7500\n",
      "Epoch 126: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2710882.5000 - mse: 2710882.5000 - val_loss: 9679396.0000 - val_mse: 9679396.0000\n",
      "Epoch 127/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 2965719.7500 - mse: 2965719.7500\n",
      "Epoch 127: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2948213.5000 - mse: 2948213.5000 - val_loss: 11712663.0000 - val_mse: 11712663.0000\n",
      "Epoch 128/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2799823.7500 - mse: 2799823.7500\n",
      "Epoch 128: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2804587.2500 - mse: 2804587.2500 - val_loss: 9991300.0000 - val_mse: 9991300.0000\n",
      "Epoch 129/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2406279.7500 - mse: 2406279.7500\n",
      "Epoch 129: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2414524.7500 - mse: 2414524.7500 - val_loss: 11064740.0000 - val_mse: 11064740.0000\n",
      "Epoch 130/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2661500.2500 - mse: 2661500.2500\n",
      "Epoch 130: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2639840.2500 - mse: 2639840.2500 - val_loss: 11971733.0000 - val_mse: 11971733.0000\n",
      "Epoch 131/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2247580.0000 - mse: 2247580.0000\n",
      "Epoch 131: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2262196.0000 - mse: 2262196.0000 - val_loss: 11265019.0000 - val_mse: 11265019.0000\n",
      "Epoch 132/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 2187329.2500 - mse: 2187329.2500\n",
      "Epoch 132: loss did not improve from 2181332.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2237886.2500 - mse: 2237886.2500 - val_loss: 12308448.0000 - val_mse: 12308448.0000\n",
      "Epoch 133/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2138792.2500 - mse: 2138792.2500\n",
      "Epoch 133: loss improved from 2181332.50000 to 2142355.00000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2142355.0000 - mse: 2142355.0000 - val_loss: 12272701.0000 - val_mse: 12272701.0000\n",
      "Epoch 134/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2451530.0000 - mse: 2451530.0000\n",
      "Epoch 134: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2445793.7500 - mse: 2445793.7500 - val_loss: 11442914.0000 - val_mse: 11442914.0000\n",
      "Epoch 135/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2605868.5000 - mse: 2605868.5000\n",
      "Epoch 135: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2569005.7500 - mse: 2569005.7500 - val_loss: 12928870.0000 - val_mse: 12928870.0000\n",
      "Epoch 136/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2480865.2500 - mse: 2480865.2500\n",
      "Epoch 136: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2486871.5000 - mse: 2486871.5000 - val_loss: 11054206.0000 - val_mse: 11054206.0000\n",
      "Epoch 137/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2434836.5000 - mse: 2434836.5000\n",
      "Epoch 137: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2436762.0000 - mse: 2436762.0000 - val_loss: 12365834.0000 - val_mse: 12365834.0000\n",
      "Epoch 138/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2703578.7500 - mse: 2703578.7500\n",
      "Epoch 138: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2707370.7500 - mse: 2707370.7500 - val_loss: 10111174.0000 - val_mse: 10111174.0000\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2632351.2500 - mse: 2632351.2500\n",
      "Epoch 139: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2632351.2500 - mse: 2632351.2500 - val_loss: 11287564.0000 - val_mse: 11287564.0000\n",
      "Epoch 140/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2574904.5000 - mse: 2574904.5000\n",
      "Epoch 140: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2558970.7500 - mse: 2558970.7500 - val_loss: 11752676.0000 - val_mse: 11752676.0000\n",
      "Epoch 141/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2576813.5000 - mse: 2576813.5000\n",
      "Epoch 141: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2567073.2500 - mse: 2567073.2500 - val_loss: 11453836.0000 - val_mse: 11453836.0000\n",
      "Epoch 142/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2390698.7500 - mse: 2390698.7500\n",
      "Epoch 142: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2401438.7500 - mse: 2401438.7500 - val_loss: 10838026.0000 - val_mse: 10838026.0000\n",
      "Epoch 143/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2498737.2500 - mse: 2498737.2500\n",
      "Epoch 143: loss did not improve from 2142355.00000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2523314.0000 - mse: 2523314.0000 - val_loss: 12078209.0000 - val_mse: 12078209.0000\n",
      "Epoch 144/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1765025.1250 - mse: 1765025.1250\n",
      "Epoch 144: loss improved from 2142355.00000 to 1764299.62500, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1764299.6250 - mse: 1764299.6250 - val_loss: 10944516.0000 - val_mse: 10944516.0000\n",
      "Epoch 145/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2186573.0000 - mse: 2186573.0000\n",
      "Epoch 145: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2194474.5000 - mse: 2194474.5000 - val_loss: 12066441.0000 - val_mse: 12066441.0000\n",
      "Epoch 146/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2151804.5000 - mse: 2151804.5000\n",
      "Epoch 146: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2127636.7500 - mse: 2127636.7500 - val_loss: 11384455.0000 - val_mse: 11384455.0000\n",
      "Epoch 147/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2263996.5000 - mse: 2263996.5000\n",
      "Epoch 147: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2264393.7500 - mse: 2264393.7500 - val_loss: 11884417.0000 - val_mse: 11884417.0000\n",
      "Epoch 148/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2320399.2500 - mse: 2320399.2500\n",
      "Epoch 148: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2298867.0000 - mse: 2298867.0000 - val_loss: 11395044.0000 - val_mse: 11395044.0000\n",
      "Epoch 149/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2295743.7500 - mse: 2295743.7500\n",
      "Epoch 149: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2296645.7500 - mse: 2296645.7500 - val_loss: 11994898.0000 - val_mse: 11994898.0000\n",
      "Epoch 150/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2285761.7500 - mse: 2285761.7500\n",
      "Epoch 150: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2248288.2500 - mse: 2248288.2500 - val_loss: 13115874.0000 - val_mse: 13115874.0000\n",
      "Epoch 151/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2359683.2500 - mse: 2359683.2500\n",
      "Epoch 151: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2365167.7500 - mse: 2365167.7500 - val_loss: 11768359.0000 - val_mse: 11768359.0000\n",
      "Epoch 152/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2470500.5000 - mse: 2470500.5000\n",
      "Epoch 152: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2458412.7500 - mse: 2458412.7500 - val_loss: 11404524.0000 - val_mse: 11404524.0000\n",
      "Epoch 153/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2412096.0000 - mse: 2412096.0000\n",
      "Epoch 153: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2422106.7500 - mse: 2422106.7500 - val_loss: 13341300.0000 - val_mse: 13341300.0000\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2141930.5000 - mse: 2141930.5000\n",
      "Epoch 154: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2141930.5000 - mse: 2141930.5000 - val_loss: 11439326.0000 - val_mse: 11439326.0000\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2424826.7500 - mse: 2424826.7500\n",
      "Epoch 155: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2424826.7500 - mse: 2424826.7500 - val_loss: 12100310.0000 - val_mse: 12100310.0000\n",
      "Epoch 156/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2310658.5000 - mse: 2310658.5000\n",
      "Epoch 156: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2322145.0000 - mse: 2322145.0000 - val_loss: 10635082.0000 - val_mse: 10635082.0000\n",
      "Epoch 157/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 2951580.2500 - mse: 2951580.2500\n",
      "Epoch 157: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2926843.0000 - mse: 2926843.0000 - val_loss: 6942612.0000 - val_mse: 6942612.0000\n",
      "Epoch 158/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 3006511.2500 - mse: 3006511.2500\n",
      "Epoch 158: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3022466.5000 - mse: 3022466.5000 - val_loss: 8635918.0000 - val_mse: 8635918.0000\n",
      "Epoch 159/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2721345.2500 - mse: 2721345.2500\n",
      "Epoch 159: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2719762.5000 - mse: 2719762.5000 - val_loss: 5602753.0000 - val_mse: 5602753.0000\n",
      "Epoch 160/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2642130.5000 - mse: 2642130.5000\n",
      "Epoch 160: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2664456.5000 - mse: 2664456.5000 - val_loss: 8435881.0000 - val_mse: 8435881.0000\n",
      "Epoch 161/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2725774.0000 - mse: 2725774.0000\n",
      "Epoch 161: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2710931.7500 - mse: 2710931.7500 - val_loss: 8920788.0000 - val_mse: 8920788.0000\n",
      "Epoch 162/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2638211.2500 - mse: 2638211.2500\n",
      "Epoch 162: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2636199.2500 - mse: 2636199.2500 - val_loss: 9901300.0000 - val_mse: 9901300.0000\n",
      "Epoch 163/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2770347.7500 - mse: 2770347.7500\n",
      "Epoch 163: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2770620.2500 - mse: 2770620.2500 - val_loss: 8051696.0000 - val_mse: 8051696.0000\n",
      "Epoch 164/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2853304.5000 - mse: 2853304.5000\n",
      "Epoch 164: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2872470.7500 - mse: 2872470.7500 - val_loss: 7182653.5000 - val_mse: 7182653.5000\n",
      "Epoch 165/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2825019.0000 - mse: 2825019.0000\n",
      "Epoch 165: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2814320.7500 - mse: 2814320.7500 - val_loss: 8158478.5000 - val_mse: 8158478.5000\n",
      "Epoch 166/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2743396.7500 - mse: 2743396.7500\n",
      "Epoch 166: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2748657.2500 - mse: 2748657.2500 - val_loss: 6596597.5000 - val_mse: 6596597.5000\n",
      "Epoch 167/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2454488.0000 - mse: 2454488.0000\n",
      "Epoch 167: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2435395.0000 - mse: 2435395.0000 - val_loss: 6279670.0000 - val_mse: 6279670.0000\n",
      "Epoch 168/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2818959.2500 - mse: 2818959.2500\n",
      "Epoch 168: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2844557.5000 - mse: 2844557.5000 - val_loss: 9191664.0000 - val_mse: 9191664.0000\n",
      "Epoch 169/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2108559.7500 - mse: 2108559.7500\n",
      "Epoch 169: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2126738.0000 - mse: 2126738.0000 - val_loss: 7891146.0000 - val_mse: 7891146.0000\n",
      "Epoch 170/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2574346.2500 - mse: 2574346.2500\n",
      "Epoch 170: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2562009.5000 - mse: 2562009.5000 - val_loss: 8272870.0000 - val_mse: 8272870.0000\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2566497.5000 - mse: 2566497.5000\n",
      "Epoch 171: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2566497.5000 - mse: 2566497.5000 - val_loss: 7486414.0000 - val_mse: 7486414.0000\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2622622.2500 - mse: 2622622.2500\n",
      "Epoch 172: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2622622.2500 - mse: 2622622.2500 - val_loss: 7833754.0000 - val_mse: 7833754.0000\n",
      "Epoch 173/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2705205.2500 - mse: 2705205.2500\n",
      "Epoch 173: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2691827.5000 - mse: 2691827.5000 - val_loss: 7785784.0000 - val_mse: 7785784.0000\n",
      "Epoch 174/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2449491.5000 - mse: 2449491.5000\n",
      "Epoch 174: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2461376.5000 - mse: 2461376.5000 - val_loss: 7041734.0000 - val_mse: 7041734.0000\n",
      "Epoch 175/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2581382.5000 - mse: 2581382.5000\n",
      "Epoch 175: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2588454.0000 - mse: 2588454.0000 - val_loss: 7644147.0000 - val_mse: 7644147.0000\n",
      "Epoch 176/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2570749.2500 - mse: 2570749.2500\n",
      "Epoch 176: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2572268.5000 - mse: 2572268.5000 - val_loss: 6910264.5000 - val_mse: 6910264.5000\n",
      "Epoch 177/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2474894.7500 - mse: 2474894.7500\n",
      "Epoch 177: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2504956.2500 - mse: 2504956.2500 - val_loss: 7757161.0000 - val_mse: 7757161.0000\n",
      "Epoch 178/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2419033.5000 - mse: 2419033.5000\n",
      "Epoch 178: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2393136.5000 - mse: 2393136.5000 - val_loss: 9190511.0000 - val_mse: 9190511.0000\n",
      "Epoch 179/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2176280.0000 - mse: 2176280.0000\n",
      "Epoch 179: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2183739.0000 - mse: 2183739.0000 - val_loss: 7096990.0000 - val_mse: 7096990.0000\n",
      "Epoch 180/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2549693.2500 - mse: 2549693.2500\n",
      "Epoch 180: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2555780.7500 - mse: 2555780.7500 - val_loss: 7979294.5000 - val_mse: 7979294.5000\n",
      "Epoch 181/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 2206824.7500 - mse: 2206824.7500\n",
      "Epoch 181: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2199197.0000 - mse: 2199197.0000 - val_loss: 7710758.0000 - val_mse: 7710758.0000\n",
      "Epoch 182/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2394767.7500 - mse: 2394767.7500\n",
      "Epoch 182: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2402759.2500 - mse: 2402759.2500 - val_loss: 9015970.0000 - val_mse: 9015970.0000\n",
      "Epoch 183/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1934096.0000 - mse: 1934096.0000\n",
      "Epoch 183: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1932672.7500 - mse: 1932672.7500 - val_loss: 8045230.0000 - val_mse: 8045230.0000\n",
      "Epoch 184/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2186583.0000 - mse: 2186583.0000\n",
      "Epoch 184: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2190028.0000 - mse: 2190028.0000 - val_loss: 7753421.0000 - val_mse: 7753421.0000\n",
      "Epoch 185/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2200768.0000 - mse: 2200768.0000\n",
      "Epoch 185: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2216645.0000 - mse: 2216645.0000 - val_loss: 7630901.0000 - val_mse: 7630901.0000\n",
      "Epoch 186/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2256925.5000 - mse: 2256925.5000\n",
      "Epoch 186: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2262041.5000 - mse: 2262041.5000 - val_loss: 7094394.0000 - val_mse: 7094394.0000\n",
      "Epoch 187/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2574111.7500 - mse: 2574111.7500\n",
      "Epoch 187: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2553619.0000 - mse: 2553619.0000 - val_loss: 8871808.0000 - val_mse: 8871808.0000\n",
      "Epoch 188/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2527314.5000 - mse: 2527314.5000\n",
      "Epoch 188: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2538121.0000 - mse: 2538121.0000 - val_loss: 7998425.5000 - val_mse: 7998425.5000\n",
      "Epoch 189/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2345691.5000 - mse: 2345691.5000\n",
      "Epoch 189: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2336662.2500 - mse: 2336662.2500 - val_loss: 8104749.0000 - val_mse: 8104749.0000\n",
      "Epoch 190/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2518698.5000 - mse: 2518698.5000\n",
      "Epoch 190: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2503560.0000 - mse: 2503560.0000 - val_loss: 8187192.0000 - val_mse: 8187192.0000\n",
      "Epoch 191/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2511003.7500 - mse: 2511003.7500\n",
      "Epoch 191: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2503101.0000 - mse: 2503101.0000 - val_loss: 7560475.0000 - val_mse: 7560475.0000\n",
      "Epoch 192/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2515212.5000 - mse: 2515212.5000\n",
      "Epoch 192: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2514610.0000 - mse: 2514610.0000 - val_loss: 8792328.0000 - val_mse: 8792328.0000\n",
      "Epoch 193/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2723942.7500 - mse: 2723942.7500\n",
      "Epoch 193: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2687512.7500 - mse: 2687512.7500 - val_loss: 7618524.0000 - val_mse: 7618524.0000\n",
      "Epoch 194/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1765679.5000 - mse: 1765679.5000\n",
      "Epoch 194: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1809712.1250 - mse: 1809712.1250 - val_loss: 7449092.0000 - val_mse: 7449092.0000\n",
      "Epoch 195/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 2370891.2500 - mse: 2370891.2500\n",
      "Epoch 195: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2372761.2500 - mse: 2372761.2500 - val_loss: 7647783.0000 - val_mse: 7647783.0000\n",
      "Epoch 196/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2124489.7500 - mse: 2124489.7500\n",
      "Epoch 196: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2118393.0000 - mse: 2118393.0000 - val_loss: 8193723.0000 - val_mse: 8193723.0000\n",
      "Epoch 197/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2253127.5000 - mse: 2253127.5000\n",
      "Epoch 197: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2264019.7500 - mse: 2264019.7500 - val_loss: 7827660.5000 - val_mse: 7827660.5000\n",
      "Epoch 198/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2284514.2500 - mse: 2284514.2500\n",
      "Epoch 198: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2272055.7500 - mse: 2272055.7500 - val_loss: 7962778.0000 - val_mse: 7962778.0000\n",
      "Epoch 199/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2333927.7500 - mse: 2333927.7500\n",
      "Epoch 199: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2329745.7500 - mse: 2329745.7500 - val_loss: 9011495.0000 - val_mse: 9011495.0000\n",
      "Epoch 200/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 2280514.7500 - mse: 2280514.7500\n",
      "Epoch 200: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2329300.0000 - mse: 2329300.0000 - val_loss: 9168371.0000 - val_mse: 9168371.0000\n",
      "Epoch 201/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2171931.5000 - mse: 2171931.5000\n",
      "Epoch 201: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2188069.2500 - mse: 2188069.2500 - val_loss: 9054980.0000 - val_mse: 9054980.0000\n",
      "Epoch 202/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2415304.0000 - mse: 2415304.0000\n",
      "Epoch 202: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2485123.2500 - mse: 2485123.2500 - val_loss: 8476621.0000 - val_mse: 8476621.0000\n",
      "Epoch 203/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2316001.2500 - mse: 2316001.2500\n",
      "Epoch 203: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2330477.2500 - mse: 2330477.2500 - val_loss: 8591344.0000 - val_mse: 8591344.0000\n",
      "Epoch 204/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2132931.0000 - mse: 2132931.0000\n",
      "Epoch 204: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2122073.7500 - mse: 2122073.7500 - val_loss: 8704988.0000 - val_mse: 8704988.0000\n",
      "Epoch 205/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2331386.0000 - mse: 2331386.0000\n",
      "Epoch 205: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2350885.2500 - mse: 2350885.2500 - val_loss: 9065795.0000 - val_mse: 9065795.0000\n",
      "Epoch 206/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2164271.5000 - mse: 2164271.5000\n",
      "Epoch 206: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2171536.0000 - mse: 2171536.0000 - val_loss: 9000252.0000 - val_mse: 9000252.0000\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1944961.6250 - mse: 1944961.6250\n",
      "Epoch 207: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1944961.6250 - mse: 1944961.6250 - val_loss: 8239248.0000 - val_mse: 8239248.0000\n",
      "Epoch 208/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1947895.0000 - mse: 1947895.0000\n",
      "Epoch 208: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1956331.6250 - mse: 1956331.6250 - val_loss: 7211036.0000 - val_mse: 7211036.0000\n",
      "Epoch 209/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2142067.5000 - mse: 2142067.5000\n",
      "Epoch 209: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2115046.5000 - mse: 2115046.5000 - val_loss: 7856090.0000 - val_mse: 7856090.0000\n",
      "Epoch 210/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2152211.2500 - mse: 2152211.2500\n",
      "Epoch 210: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2124200.0000 - mse: 2124200.0000 - val_loss: 8251161.0000 - val_mse: 8251161.0000\n",
      "Epoch 211/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2175312.0000 - mse: 2175312.0000\n",
      "Epoch 211: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2171034.5000 - mse: 2171034.5000 - val_loss: 7282124.0000 - val_mse: 7282124.0000\n",
      "Epoch 212/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2041509.5000 - mse: 2041509.5000\n",
      "Epoch 212: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2048133.1250 - mse: 2048133.1250 - val_loss: 8641708.0000 - val_mse: 8641708.0000\n",
      "Epoch 213/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2218675.5000 - mse: 2218675.5000\n",
      "Epoch 213: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2224578.0000 - mse: 2224578.0000 - val_loss: 8447495.0000 - val_mse: 8447495.0000\n",
      "Epoch 214/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2208472.2500 - mse: 2208472.2500\n",
      "Epoch 214: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2258046.5000 - mse: 2258046.5000 - val_loss: 7805895.5000 - val_mse: 7805895.5000\n",
      "Epoch 215/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2206794.0000 - mse: 2206794.0000\n",
      "Epoch 215: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2193284.7500 - mse: 2193284.7500 - val_loss: 8840817.0000 - val_mse: 8840817.0000\n",
      "Epoch 216/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2060154.6250 - mse: 2060154.6250\n",
      "Epoch 216: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2000511.2500 - mse: 2000511.2500 - val_loss: 9184646.0000 - val_mse: 9184646.0000\n",
      "Epoch 217/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1933994.6250 - mse: 1933994.6250\n",
      "Epoch 217: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1974759.8750 - mse: 1974759.8750 - val_loss: 8646374.0000 - val_mse: 8646374.0000\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2146230.2500 - mse: 2146230.2500\n",
      "Epoch 218: loss did not improve from 1764299.62500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2146230.2500 - mse: 2146230.2500 - val_loss: 8506310.0000 - val_mse: 8506310.0000\n",
      "Epoch 219/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1491185.0000 - mse: 1491185.0000\n",
      "Epoch 219: loss improved from 1764299.62500 to 1522740.12500, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1522740.1250 - mse: 1522740.1250 - val_loss: 10079478.0000 - val_mse: 10079478.0000\n",
      "Epoch 220/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1880387.1250 - mse: 1880387.1250\n",
      "Epoch 220: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1865611.3750 - mse: 1865611.3750 - val_loss: 9168750.0000 - val_mse: 9168750.0000\n",
      "Epoch 221/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1851484.0000 - mse: 1851484.0000\n",
      "Epoch 221: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1852327.8750 - mse: 1852327.8750 - val_loss: 9230211.0000 - val_mse: 9230211.0000\n",
      "Epoch 222/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1906445.8750 - mse: 1906445.8750\n",
      "Epoch 222: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1900663.0000 - mse: 1900663.0000 - val_loss: 8206150.0000 - val_mse: 8206150.0000\n",
      "Epoch 223/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1930425.7500 - mse: 1930425.7500\n",
      "Epoch 223: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1932420.0000 - mse: 1932420.0000 - val_loss: 8989824.0000 - val_mse: 8989824.0000\n",
      "Epoch 224/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1854321.6250 - mse: 1854321.6250\n",
      "Epoch 224: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1848110.8750 - mse: 1848110.8750 - val_loss: 7929357.0000 - val_mse: 7929357.0000\n",
      "Epoch 225/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2032322.1250 - mse: 2032322.1250\n",
      "Epoch 225: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2000166.3750 - mse: 2000166.3750 - val_loss: 8849637.0000 - val_mse: 8849637.0000\n",
      "Epoch 226/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2069638.1250 - mse: 2069638.1250\n",
      "Epoch 226: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2034804.5000 - mse: 2034804.5000 - val_loss: 9469740.0000 - val_mse: 9469740.0000\n",
      "Epoch 227/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2128595.7500 - mse: 2128595.7500\n",
      "Epoch 227: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2125800.2500 - mse: 2125800.2500 - val_loss: 7169765.0000 - val_mse: 7169765.0000\n",
      "Epoch 228/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2055662.0000 - mse: 2055662.0000\n",
      "Epoch 228: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2058253.8750 - mse: 2058253.8750 - val_loss: 7627057.0000 - val_mse: 7627057.0000\n",
      "Epoch 229/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1847545.8750 - mse: 1847545.8750\n",
      "Epoch 229: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1887269.7500 - mse: 1887269.7500 - val_loss: 7989178.0000 - val_mse: 7989178.0000\n",
      "Epoch 230/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2040606.0000 - mse: 2040606.0000\n",
      "Epoch 230: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2059670.1250 - mse: 2059670.1250 - val_loss: 8481326.0000 - val_mse: 8481326.0000\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1829796.3750 - mse: 1829796.3750\n",
      "Epoch 231: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1829796.3750 - mse: 1829796.3750 - val_loss: 8176414.0000 - val_mse: 8176414.0000\n",
      "Epoch 232/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1724314.2500 - mse: 1724314.2500\n",
      "Epoch 232: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1740959.2500 - mse: 1740959.2500 - val_loss: 7330374.0000 - val_mse: 7330374.0000\n",
      "Epoch 233/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1664063.6250 - mse: 1664063.6250\n",
      "Epoch 233: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1687190.3750 - mse: 1687190.3750 - val_loss: 8234014.5000 - val_mse: 8234014.5000\n",
      "Epoch 234/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1784375.6250 - mse: 1784375.6250\n",
      "Epoch 234: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1790969.1250 - mse: 1790969.1250 - val_loss: 7654510.5000 - val_mse: 7654510.5000\n",
      "Epoch 235/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1877744.8750 - mse: 1877744.8750\n",
      "Epoch 235: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1867242.2500 - mse: 1867242.2500 - val_loss: 8928031.0000 - val_mse: 8928031.0000\n",
      "Epoch 236/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1923487.3750 - mse: 1923487.3750\n",
      "Epoch 236: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1921419.0000 - mse: 1921419.0000 - val_loss: 9169320.0000 - val_mse: 9169320.0000\n",
      "Epoch 237/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1862430.2500 - mse: 1862430.2500\n",
      "Epoch 237: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1854534.5000 - mse: 1854534.5000 - val_loss: 9403310.0000 - val_mse: 9403310.0000\n",
      "Epoch 238/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2063220.0000 - mse: 2063220.0000\n",
      "Epoch 238: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2050119.3750 - mse: 2050119.3750 - val_loss: 7630135.0000 - val_mse: 7630135.0000\n",
      "Epoch 239/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2123998.2500 - mse: 2123998.2500\n",
      "Epoch 239: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2137132.2500 - mse: 2137132.2500 - val_loss: 8284996.5000 - val_mse: 8284996.5000\n",
      "Epoch 240/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2085022.6250 - mse: 2085022.6250\n",
      "Epoch 240: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2089525.1250 - mse: 2089525.1250 - val_loss: 7590576.0000 - val_mse: 7590576.0000\n",
      "Epoch 241/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1860343.3750 - mse: 1860343.3750\n",
      "Epoch 241: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1848548.3750 - mse: 1848548.3750 - val_loss: 9643118.0000 - val_mse: 9643118.0000\n",
      "Epoch 242/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2084376.6250 - mse: 2084376.6250\n",
      "Epoch 242: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2071650.1250 - mse: 2071650.1250 - val_loss: 9974871.0000 - val_mse: 9974871.0000\n",
      "Epoch 243/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2084645.6250 - mse: 2084645.6250\n",
      "Epoch 243: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2042237.2500 - mse: 2042237.2500 - val_loss: 9417091.0000 - val_mse: 9417091.0000\n",
      "Epoch 244/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1559295.6250 - mse: 1559295.6250\n",
      "Epoch 244: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1563410.1250 - mse: 1563410.1250 - val_loss: 9266406.0000 - val_mse: 9266406.0000\n",
      "Epoch 245/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1641761.5000 - mse: 1641761.5000\n",
      "Epoch 245: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1648311.3750 - mse: 1648311.3750 - val_loss: 7747527.0000 - val_mse: 7747527.0000\n",
      "Epoch 246/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1802074.3750 - mse: 1802074.3750\n",
      "Epoch 246: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1777851.5000 - mse: 1777851.5000 - val_loss: 8678184.0000 - val_mse: 8678184.0000\n",
      "Epoch 247/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1851292.7500 - mse: 1851292.7500\n",
      "Epoch 247: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1847231.6250 - mse: 1847231.6250 - val_loss: 9548586.0000 - val_mse: 9548586.0000\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1856372.3750 - mse: 1856372.3750\n",
      "Epoch 248: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1856372.3750 - mse: 1856372.3750 - val_loss: 9561476.0000 - val_mse: 9561476.0000\n",
      "Epoch 249/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1893717.1250 - mse: 1893717.1250\n",
      "Epoch 249: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1894225.1250 - mse: 1894225.1250 - val_loss: 7994463.0000 - val_mse: 7994463.0000\n",
      "Epoch 250/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1875114.6250 - mse: 1875114.6250\n",
      "Epoch 250: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1879059.7500 - mse: 1879059.7500 - val_loss: 8867744.0000 - val_mse: 8867744.0000\n",
      "Epoch 251/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2119086.7500 - mse: 2119086.7500\n",
      "Epoch 251: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2119448.2500 - mse: 2119448.2500 - val_loss: 7311151.0000 - val_mse: 7311151.0000\n",
      "Epoch 252/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 2094628.1250 - mse: 2094628.1250\n",
      "Epoch 252: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2054170.1250 - mse: 2054170.1250 - val_loss: 9426890.0000 - val_mse: 9426890.0000\n",
      "Epoch 253/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2063433.7500 - mse: 2063433.7500\n",
      "Epoch 253: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2045086.7500 - mse: 2045086.7500 - val_loss: 9027834.0000 - val_mse: 9027834.0000\n",
      "Epoch 254/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1862620.0000 - mse: 1862620.0000\n",
      "Epoch 254: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1860172.7500 - mse: 1860172.7500 - val_loss: 7212482.0000 - val_mse: 7212482.0000\n",
      "Epoch 255/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1962626.0000 - mse: 1962626.0000\n",
      "Epoch 255: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2000113.8750 - mse: 2000113.8750 - val_loss: 7914359.0000 - val_mse: 7914359.0000\n",
      "Epoch 256/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1804688.6250 - mse: 1804688.6250\n",
      "Epoch 256: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1793929.5000 - mse: 1793929.5000 - val_loss: 9136956.0000 - val_mse: 9136956.0000\n",
      "Epoch 257/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1733629.2500 - mse: 1733629.2500\n",
      "Epoch 257: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1707037.6250 - mse: 1707037.6250 - val_loss: 11009658.0000 - val_mse: 11009658.0000\n",
      "Epoch 258/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1758762.3750 - mse: 1758762.3750\n",
      "Epoch 258: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1762508.5000 - mse: 1762508.5000 - val_loss: 8393787.0000 - val_mse: 8393787.0000\n",
      "Epoch 259/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1909610.5000 - mse: 1909610.5000\n",
      "Epoch 259: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1923642.3750 - mse: 1923642.3750 - val_loss: 8610583.0000 - val_mse: 8610583.0000\n",
      "Epoch 260/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1823260.1250 - mse: 1823260.1250\n",
      "Epoch 260: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1854055.0000 - mse: 1854055.0000 - val_loss: 7420318.5000 - val_mse: 7420318.5000\n",
      "Epoch 261/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1787425.8750 - mse: 1787425.8750\n",
      "Epoch 261: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1787376.3750 - mse: 1787376.3750 - val_loss: 9426908.0000 - val_mse: 9426908.0000\n",
      "Epoch 262/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1825618.2500 - mse: 1825618.2500\n",
      "Epoch 262: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1811597.5000 - mse: 1811597.5000 - val_loss: 8264463.0000 - val_mse: 8264463.0000\n",
      "Epoch 263/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1945059.1250 - mse: 1945059.1250\n",
      "Epoch 263: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1958270.3750 - mse: 1958270.3750 - val_loss: 8007684.5000 - val_mse: 8007684.5000\n",
      "Epoch 264/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2130377.2500 - mse: 2130377.2500\n",
      "Epoch 264: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2129529.0000 - mse: 2129529.0000 - val_loss: 8897422.0000 - val_mse: 8897422.0000\n",
      "Epoch 265/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1918820.5000 - mse: 1918820.5000\n",
      "Epoch 265: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1941799.6250 - mse: 1941799.6250 - val_loss: 7283117.0000 - val_mse: 7283117.0000\n",
      "Epoch 266/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1841308.0000 - mse: 1841308.0000\n",
      "Epoch 266: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1856223.0000 - mse: 1856223.0000 - val_loss: 8488973.0000 - val_mse: 8488973.0000\n",
      "Epoch 267/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1993095.1250 - mse: 1993095.1250\n",
      "Epoch 267: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2010863.0000 - mse: 2010863.0000 - val_loss: 8182186.0000 - val_mse: 8182186.0000\n",
      "Epoch 268/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2027889.3750 - mse: 2027889.3750\n",
      "Epoch 268: loss did not improve from 1522740.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1965655.2500 - mse: 1965655.2500 - val_loss: 9258102.0000 - val_mse: 9258102.0000\n",
      "Epoch 269/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1513112.6250 - mse: 1513112.6250\n",
      "Epoch 269: loss improved from 1522740.12500 to 1507493.50000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1507493.5000 - mse: 1507493.5000 - val_loss: 7501406.0000 - val_mse: 7501406.0000\n",
      "Epoch 270/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1835676.6250 - mse: 1835676.6250\n",
      "Epoch 270: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1828986.3750 - mse: 1828986.3750 - val_loss: 8464171.0000 - val_mse: 8464171.0000\n",
      "Epoch 271/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1692089.6250 - mse: 1692089.6250\n",
      "Epoch 271: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1695387.8750 - mse: 1695387.8750 - val_loss: 7018162.5000 - val_mse: 7018162.5000\n",
      "Epoch 272/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2045715.8750 - mse: 2045715.8750\n",
      "Epoch 272: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2039820.1250 - mse: 2039820.1250 - val_loss: 7878327.0000 - val_mse: 7878327.0000\n",
      "Epoch 273/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1845044.5000 - mse: 1845044.5000\n",
      "Epoch 273: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1844700.6250 - mse: 1844700.6250 - val_loss: 8037866.0000 - val_mse: 8037866.0000\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1874673.6250 - mse: 1874673.6250\n",
      "Epoch 274: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1874673.6250 - mse: 1874673.6250 - val_loss: 7668884.5000 - val_mse: 7668884.5000\n",
      "Epoch 275/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1878288.6250 - mse: 1878288.6250\n",
      "Epoch 275: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1876645.2500 - mse: 1876645.2500 - val_loss: 6224135.0000 - val_mse: 6224135.0000\n",
      "Epoch 276/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2075005.7500 - mse: 2075005.7500\n",
      "Epoch 276: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2091539.0000 - mse: 2091539.0000 - val_loss: 7782256.0000 - val_mse: 7782256.0000\n",
      "Epoch 277/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2156363.0000 - mse: 2156363.0000\n",
      "Epoch 277: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2157999.0000 - mse: 2157999.0000 - val_loss: 7695444.0000 - val_mse: 7695444.0000\n",
      "Epoch 278/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1959146.3750 - mse: 1959146.3750\n",
      "Epoch 278: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1943412.1250 - mse: 1943412.1250 - val_loss: 7497176.0000 - val_mse: 7497176.0000\n",
      "Epoch 279/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1896711.0000 - mse: 1896711.0000\n",
      "Epoch 279: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1887095.8750 - mse: 1887095.8750 - val_loss: 8055997.5000 - val_mse: 8055997.5000\n",
      "Epoch 280/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2209836.0000 - mse: 2209836.0000\n",
      "Epoch 280: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2200863.7500 - mse: 2200863.7500 - val_loss: 9062346.0000 - val_mse: 9062346.0000\n",
      "Epoch 281/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1708859.3750 - mse: 1708859.3750\n",
      "Epoch 281: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1675547.3750 - mse: 1675547.3750 - val_loss: 9091902.0000 - val_mse: 9091902.0000\n",
      "Epoch 282/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1723093.7500 - mse: 1723093.7500\n",
      "Epoch 282: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1724995.3750 - mse: 1724995.3750 - val_loss: 8635290.0000 - val_mse: 8635290.0000\n",
      "Epoch 283/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2332849.2500 - mse: 2332849.2500\n",
      "Epoch 283: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2313029.5000 - mse: 2313029.5000 - val_loss: 8205050.0000 - val_mse: 8205050.0000\n",
      "Epoch 284/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2252543.2500 - mse: 2252543.2500\n",
      "Epoch 284: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2237350.5000 - mse: 2237350.5000 - val_loss: 7666701.0000 - val_mse: 7666701.0000\n",
      "Epoch 285/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1987568.1250 - mse: 1987568.1250\n",
      "Epoch 285: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1993435.2500 - mse: 1993435.2500 - val_loss: 7469742.0000 - val_mse: 7469742.0000\n",
      "Epoch 286/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1918933.2500 - mse: 1918933.2500\n",
      "Epoch 286: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1933503.5000 - mse: 1933503.5000 - val_loss: 6618403.0000 - val_mse: 6618403.0000\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2038503.2500 - mse: 2038503.2500\n",
      "Epoch 287: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2038503.2500 - mse: 2038503.2500 - val_loss: 7213041.0000 - val_mse: 7213041.0000\n",
      "Epoch 288/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 2214786.5000 - mse: 2214786.5000\n",
      "Epoch 288: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2229134.7500 - mse: 2229134.7500 - val_loss: 7323705.0000 - val_mse: 7323705.0000\n",
      "Epoch 289/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2091711.3750 - mse: 2091711.3750\n",
      "Epoch 289: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2078429.7500 - mse: 2078429.7500 - val_loss: 8195386.0000 - val_mse: 8195386.0000\n",
      "Epoch 290/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 2061093.8750 - mse: 2061093.8750\n",
      "Epoch 290: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2044185.2500 - mse: 2044185.2500 - val_loss: 7947903.0000 - val_mse: 7947903.0000\n",
      "Epoch 291/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1881169.5000 - mse: 1881169.5000\n",
      "Epoch 291: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1870842.2500 - mse: 1870842.2500 - val_loss: 6851995.0000 - val_mse: 6851995.0000\n",
      "Epoch 292/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2139685.2500 - mse: 2139685.2500\n",
      "Epoch 292: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2147481.5000 - mse: 2147481.5000 - val_loss: 7718458.0000 - val_mse: 7718458.0000\n",
      "Epoch 293/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1949764.5000 - mse: 1949764.5000\n",
      "Epoch 293: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1912889.1250 - mse: 1912889.1250 - val_loss: 9767615.0000 - val_mse: 9767615.0000\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1704221.0000 - mse: 1704221.0000\n",
      "Epoch 294: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1704221.0000 - mse: 1704221.0000 - val_loss: 7601394.5000 - val_mse: 7601394.5000\n",
      "Epoch 295/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1830562.6250 - mse: 1830562.6250\n",
      "Epoch 295: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1819831.6250 - mse: 1819831.6250 - val_loss: 8234846.5000 - val_mse: 8234846.5000\n",
      "Epoch 296/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1880185.6250 - mse: 1880185.6250\n",
      "Epoch 296: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1890133.7500 - mse: 1890133.7500 - val_loss: 7705000.5000 - val_mse: 7705000.5000\n",
      "Epoch 297/1000\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1954958.1250 - mse: 1954958.1250\n",
      "Epoch 297: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1962793.2500 - mse: 1962793.2500 - val_loss: 8160785.0000 - val_mse: 8160785.0000\n",
      "Epoch 298/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1966537.1250 - mse: 1966537.1250\n",
      "Epoch 298: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1949403.0000 - mse: 1949403.0000 - val_loss: 9326320.0000 - val_mse: 9326320.0000\n",
      "Epoch 299/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1802987.7500 - mse: 1802987.7500\n",
      "Epoch 299: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1795926.7500 - mse: 1795926.7500 - val_loss: 9145246.0000 - val_mse: 9145246.0000\n",
      "Epoch 300/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1997876.1250 - mse: 1997876.1250\n",
      "Epoch 300: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2007891.1250 - mse: 2007891.1250 - val_loss: 7535685.0000 - val_mse: 7535685.0000\n",
      "Epoch 301/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2116013.7500 - mse: 2116013.7500\n",
      "Epoch 301: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2097327.5000 - mse: 2097327.5000 - val_loss: 10181798.0000 - val_mse: 10181798.0000\n",
      "Epoch 302/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2061488.1250 - mse: 2061488.1250\n",
      "Epoch 302: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2077852.3750 - mse: 2077852.3750 - val_loss: 5412908.0000 - val_mse: 5412908.0000\n",
      "Epoch 303/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2078055.0000 - mse: 2078055.0000\n",
      "Epoch 303: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2073414.2500 - mse: 2073414.2500 - val_loss: 8135031.0000 - val_mse: 8135031.0000\n",
      "Epoch 304/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1873498.7500 - mse: 1873498.7500\n",
      "Epoch 304: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1875845.2500 - mse: 1875845.2500 - val_loss: 7531643.5000 - val_mse: 7531643.5000\n",
      "Epoch 305/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 2258406.2500 - mse: 2258406.2500\n",
      "Epoch 305: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2204765.5000 - mse: 2204765.5000 - val_loss: 10085287.0000 - val_mse: 10085287.0000\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1715402.7500 - mse: 1715402.7500\n",
      "Epoch 306: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1715402.7500 - mse: 1715402.7500 - val_loss: 9817406.0000 - val_mse: 9817406.0000\n",
      "Epoch 307/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1808005.5000 - mse: 1808005.5000\n",
      "Epoch 307: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1832028.1250 - mse: 1832028.1250 - val_loss: 7663101.0000 - val_mse: 7663101.0000\n",
      "Epoch 308/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1590890.6250 - mse: 1590890.6250\n",
      "Epoch 308: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1616808.0000 - mse: 1616808.0000 - val_loss: 8385090.0000 - val_mse: 8385090.0000\n",
      "Epoch 309/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1756373.7500 - mse: 1756373.7500\n",
      "Epoch 309: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1753810.1250 - mse: 1753810.1250 - val_loss: 9219830.0000 - val_mse: 9219830.0000\n",
      "Epoch 310/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1845565.2500 - mse: 1845565.2500\n",
      "Epoch 310: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1831689.6250 - mse: 1831689.6250 - val_loss: 8008521.5000 - val_mse: 8008521.5000\n",
      "Epoch 311/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1883437.5000 - mse: 1883437.5000\n",
      "Epoch 311: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1922117.2500 - mse: 1922117.2500 - val_loss: 8294658.0000 - val_mse: 8294658.0000\n",
      "Epoch 312/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1830689.1250 - mse: 1830689.1250\n",
      "Epoch 312: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1844495.5000 - mse: 1844495.5000 - val_loss: 6980811.5000 - val_mse: 6980811.5000\n",
      "Epoch 313/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1985936.5000 - mse: 1985936.5000\n",
      "Epoch 313: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1985936.5000 - mse: 1985936.5000 - val_loss: 9299991.0000 - val_mse: 9299991.0000\n",
      "Epoch 314/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1932790.8750 - mse: 1932790.8750\n",
      "Epoch 314: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1929493.5000 - mse: 1929493.5000 - val_loss: 8095192.0000 - val_mse: 8095192.0000\n",
      "Epoch 315/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1956769.8750 - mse: 1956769.8750\n",
      "Epoch 315: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1953569.7500 - mse: 1953569.7500 - val_loss: 8944809.0000 - val_mse: 8944809.0000\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1783150.7500 - mse: 1783150.7500\n",
      "Epoch 316: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1783150.7500 - mse: 1783150.7500 - val_loss: 8681646.0000 - val_mse: 8681646.0000\n",
      "Epoch 317/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2089015.1250 - mse: 2089015.1250\n",
      "Epoch 317: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2093472.0000 - mse: 2093472.0000 - val_loss: 7697152.5000 - val_mse: 7697152.5000\n",
      "Epoch 318/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1792035.6250 - mse: 1792035.6250\n",
      "Epoch 318: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1763408.0000 - mse: 1763408.0000 - val_loss: 7908686.5000 - val_mse: 7908686.5000\n",
      "Epoch 319/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1697861.0000 - mse: 1697861.0000\n",
      "Epoch 319: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1739815.5000 - mse: 1739815.5000 - val_loss: 8769806.0000 - val_mse: 8769806.0000\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1683264.0000 - mse: 1683264.0000\n",
      "Epoch 320: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1683264.0000 - mse: 1683264.0000 - val_loss: 8224336.0000 - val_mse: 8224336.0000\n",
      "Epoch 321/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1852944.8750 - mse: 1852944.8750\n",
      "Epoch 321: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1838475.5000 - mse: 1838475.5000 - val_loss: 8148479.5000 - val_mse: 8148479.5000\n",
      "Epoch 322/1000\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1920347.6250 - mse: 1920347.6250\n",
      "Epoch 322: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1958676.7500 - mse: 1958676.7500 - val_loss: 8698646.0000 - val_mse: 8698646.0000\n",
      "Epoch 323/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1867010.1250 - mse: 1867010.1250\n",
      "Epoch 323: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1891113.5000 - mse: 1891113.5000 - val_loss: 10170935.0000 - val_mse: 10170935.0000\n",
      "Epoch 324/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1856850.1250 - mse: 1856850.1250\n",
      "Epoch 324: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1862706.3750 - mse: 1862706.3750 - val_loss: 9145045.0000 - val_mse: 9145045.0000\n",
      "Epoch 325/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1951819.8750 - mse: 1951819.8750\n",
      "Epoch 325: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1961726.8750 - mse: 1961726.8750 - val_loss: 8781700.0000 - val_mse: 8781700.0000\n",
      "Epoch 326/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1999828.8750 - mse: 1999828.8750\n",
      "Epoch 326: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1990744.7500 - mse: 1990744.7500 - val_loss: 8853782.0000 - val_mse: 8853782.0000\n",
      "Epoch 327/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 2120563.2500 - mse: 2120563.2500\n",
      "Epoch 327: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2087718.1250 - mse: 2087718.1250 - val_loss: 8703298.0000 - val_mse: 8703298.0000\n",
      "Epoch 328/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2080286.0000 - mse: 2080286.0000\n",
      "Epoch 328: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2094774.8750 - mse: 2094774.8750 - val_loss: 7853326.0000 - val_mse: 7853326.0000\n",
      "Epoch 329/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1742537.0000 - mse: 1742537.0000\n",
      "Epoch 329: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1743884.5000 - mse: 1743884.5000 - val_loss: 8261775.0000 - val_mse: 8261775.0000\n",
      "Epoch 330/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2022288.8750 - mse: 2022288.8750\n",
      "Epoch 330: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2003881.8750 - mse: 2003881.8750 - val_loss: 7853859.0000 - val_mse: 7853859.0000\n",
      "Epoch 331/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1645585.7500 - mse: 1645585.7500\n",
      "Epoch 331: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1629846.1250 - mse: 1629846.1250 - val_loss: 10513071.0000 - val_mse: 10513071.0000\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1826721.7500 - mse: 1826721.7500\n",
      "Epoch 332: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1826721.7500 - mse: 1826721.7500 - val_loss: 7560730.0000 - val_mse: 7560730.0000\n",
      "Epoch 333/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1704998.0000 - mse: 1704998.0000\n",
      "Epoch 333: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1709659.6250 - mse: 1709659.6250 - val_loss: 7837664.0000 - val_mse: 7837664.0000\n",
      "Epoch 334/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1825650.7500 - mse: 1825650.7500\n",
      "Epoch 334: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1834281.1250 - mse: 1834281.1250 - val_loss: 7771914.0000 - val_mse: 7771914.0000\n",
      "Epoch 335/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1797588.6250 - mse: 1797588.6250\n",
      "Epoch 335: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1793895.5000 - mse: 1793895.5000 - val_loss: 8122292.0000 - val_mse: 8122292.0000\n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1848997.7500 - mse: 1848997.7500\n",
      "Epoch 336: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1848997.7500 - mse: 1848997.7500 - val_loss: 8350439.0000 - val_mse: 8350439.0000\n",
      "Epoch 337/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1832270.0000 - mse: 1832270.0000\n",
      "Epoch 337: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1845995.6250 - mse: 1845995.6250 - val_loss: 7883782.0000 - val_mse: 7883782.0000\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1923422.2500 - mse: 1923422.2500\n",
      "Epoch 338: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1923422.2500 - mse: 1923422.2500 - val_loss: 7893582.0000 - val_mse: 7893582.0000\n",
      "Epoch 339/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 2388666.0000 - mse: 2388666.0000\n",
      "Epoch 339: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2414996.7500 - mse: 2414996.7500 - val_loss: 8029389.0000 - val_mse: 8029389.0000\n",
      "Epoch 340/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2116356.2500 - mse: 2116356.2500\n",
      "Epoch 340: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2123447.2500 - mse: 2123447.2500 - val_loss: 7674148.0000 - val_mse: 7674148.0000\n",
      "Epoch 341/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1858097.1250 - mse: 1858097.1250\n",
      "Epoch 341: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1858474.7500 - mse: 1858474.7500 - val_loss: 8618578.0000 - val_mse: 8618578.0000\n",
      "Epoch 342/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 2253275.2500 - mse: 2253275.2500\n",
      "Epoch 342: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2214143.0000 - mse: 2214143.0000 - val_loss: 7644795.5000 - val_mse: 7644795.5000\n",
      "Epoch 343/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2009639.3750 - mse: 2009639.3750\n",
      "Epoch 343: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2017044.1250 - mse: 2017044.1250 - val_loss: 8278668.0000 - val_mse: 8278668.0000\n",
      "Epoch 344/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2143852.7500 - mse: 2143852.7500\n",
      "Epoch 344: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2171465.0000 - mse: 2171465.0000 - val_loss: 8148926.0000 - val_mse: 8148926.0000\n",
      "Epoch 345/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1899340.1250 - mse: 1899340.1250\n",
      "Epoch 345: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1898075.0000 - mse: 1898075.0000 - val_loss: 8300741.5000 - val_mse: 8300741.5000\n",
      "Epoch 346/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1877343.3750 - mse: 1877343.3750\n",
      "Epoch 346: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1883448.6250 - mse: 1883448.6250 - val_loss: 8750740.0000 - val_mse: 8750740.0000\n",
      "Epoch 347/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2053438.3750 - mse: 2053438.3750\n",
      "Epoch 347: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2044497.0000 - mse: 2044497.0000 - val_loss: 7581864.5000 - val_mse: 7581864.5000\n",
      "Epoch 348/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2023183.6250 - mse: 2023183.6250\n",
      "Epoch 348: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2020459.8750 - mse: 2020459.8750 - val_loss: 8434232.0000 - val_mse: 8434232.0000\n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1891072.0000 - mse: 1891072.0000\n",
      "Epoch 349: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1891072.0000 - mse: 1891072.0000 - val_loss: 7326899.0000 - val_mse: 7326899.0000\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2043189.0000 - mse: 2043189.0000\n",
      "Epoch 350: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2043189.0000 - mse: 2043189.0000 - val_loss: 7630150.5000 - val_mse: 7630150.5000\n",
      "Epoch 351/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2128510.0000 - mse: 2128510.0000\n",
      "Epoch 351: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2140964.5000 - mse: 2140964.5000 - val_loss: 7965012.0000 - val_mse: 7965012.0000\n",
      "Epoch 352/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2296332.0000 - mse: 2296332.0000\n",
      "Epoch 352: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2302627.0000 - mse: 2302627.0000 - val_loss: 8065144.0000 - val_mse: 8065144.0000\n",
      "Epoch 353/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2337847.5000 - mse: 2337847.5000\n",
      "Epoch 353: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2299920.0000 - mse: 2299920.0000 - val_loss: 7385982.0000 - val_mse: 7385982.0000\n",
      "Epoch 354/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2004531.6250 - mse: 2004531.6250\n",
      "Epoch 354: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2022204.7500 - mse: 2022204.7500 - val_loss: 8721168.0000 - val_mse: 8721168.0000\n",
      "Epoch 355/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2115695.5000 - mse: 2115695.5000\n",
      "Epoch 355: loss did not improve from 1507493.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2123902.5000 - mse: 2123902.5000 - val_loss: 7780888.0000 - val_mse: 7780888.0000\n",
      "Epoch 356/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1501008.1250 - mse: 1501008.1250\n",
      "Epoch 356: loss improved from 1507493.50000 to 1498080.12500, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1498080.1250 - mse: 1498080.1250 - val_loss: 7949404.0000 - val_mse: 7949404.0000\n",
      "Epoch 357/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1854459.3750 - mse: 1854459.3750\n",
      "Epoch 357: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1853014.7500 - mse: 1853014.7500 - val_loss: 7355468.0000 - val_mse: 7355468.0000\n",
      "Epoch 358/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1817920.1250 - mse: 1817920.1250\n",
      "Epoch 358: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1800928.3750 - mse: 1800928.3750 - val_loss: 7423009.5000 - val_mse: 7423009.5000\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1820388.6250 - mse: 1820388.6250\n",
      "Epoch 359: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1820388.6250 - mse: 1820388.6250 - val_loss: 8315772.0000 - val_mse: 8315772.0000\n",
      "Epoch 360/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1943015.2500 - mse: 1943015.2500\n",
      "Epoch 360: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1973730.7500 - mse: 1973730.7500 - val_loss: 10879958.0000 - val_mse: 10879958.0000\n",
      "Epoch 361/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2193805.7500 - mse: 2193805.7500\n",
      "Epoch 361: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2204316.2500 - mse: 2204316.2500 - val_loss: 7726935.5000 - val_mse: 7726935.5000\n",
      "Epoch 362/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2383606.0000 - mse: 2383606.0000\n",
      "Epoch 362: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2373794.7500 - mse: 2373794.7500 - val_loss: 9568478.0000 - val_mse: 9568478.0000\n",
      "Epoch 363/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2402624.5000 - mse: 2402624.5000\n",
      "Epoch 363: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2402624.5000 - mse: 2402624.5000 - val_loss: 8635362.0000 - val_mse: 8635362.0000\n",
      "Epoch 364/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2189346.2500 - mse: 2189346.2500\n",
      "Epoch 364: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2151285.7500 - mse: 2151285.7500 - val_loss: 7012044.0000 - val_mse: 7012044.0000\n",
      "Epoch 365/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2143924.5000 - mse: 2143924.5000\n",
      "Epoch 365: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2144360.7500 - mse: 2144360.7500 - val_loss: 8329524.5000 - val_mse: 8329524.5000\n",
      "Epoch 366/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1875671.1250 - mse: 1875671.1250\n",
      "Epoch 366: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1904425.0000 - mse: 1904425.0000 - val_loss: 8322114.5000 - val_mse: 8322114.5000\n",
      "Epoch 367/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2110667.5000 - mse: 2110667.5000\n",
      "Epoch 367: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2110023.7500 - mse: 2110023.7500 - val_loss: 7953224.0000 - val_mse: 7953224.0000\n",
      "Epoch 368/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1785903.1250 - mse: 1785903.1250\n",
      "Epoch 368: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1779876.0000 - mse: 1779876.0000 - val_loss: 8059383.0000 - val_mse: 8059383.0000\n",
      "Epoch 369/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1767539.3750 - mse: 1767539.3750\n",
      "Epoch 369: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1768500.3750 - mse: 1768500.3750 - val_loss: 8739660.0000 - val_mse: 8739660.0000\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1674724.5000 - mse: 1674724.5000\n",
      "Epoch 370: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1674724.5000 - mse: 1674724.5000 - val_loss: 9084776.0000 - val_mse: 9084776.0000\n",
      "Epoch 371/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1711815.8750 - mse: 1711815.8750\n",
      "Epoch 371: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1730386.3750 - mse: 1730386.3750 - val_loss: 8291580.0000 - val_mse: 8291580.0000\n",
      "Epoch 372/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1809049.5000 - mse: 1809049.5000\n",
      "Epoch 372: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1812681.7500 - mse: 1812681.7500 - val_loss: 8119838.0000 - val_mse: 8119838.0000\n",
      "Epoch 373/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1733039.3750 - mse: 1733039.3750\n",
      "Epoch 373: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1726346.1250 - mse: 1726346.1250 - val_loss: 9446014.0000 - val_mse: 9446014.0000\n",
      "Epoch 374/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1808613.5000 - mse: 1808613.5000\n",
      "Epoch 374: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1827049.2500 - mse: 1827049.2500 - val_loss: 8287873.5000 - val_mse: 8287873.5000\n",
      "Epoch 375/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1924723.2500 - mse: 1924723.2500\n",
      "Epoch 375: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1935834.1250 - mse: 1935834.1250 - val_loss: 7632988.0000 - val_mse: 7632988.0000\n",
      "Epoch 376/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1892458.1250 - mse: 1892458.1250\n",
      "Epoch 376: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1924686.7500 - mse: 1924686.7500 - val_loss: 8007423.5000 - val_mse: 8007423.5000\n",
      "Epoch 377/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1835591.7500 - mse: 1835591.7500\n",
      "Epoch 377: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1843530.1250 - mse: 1843530.1250 - val_loss: 7333383.5000 - val_mse: 7333383.5000\n",
      "Epoch 378/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1899910.3750 - mse: 1899910.3750\n",
      "Epoch 378: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1905838.2500 - mse: 1905838.2500 - val_loss: 8450696.0000 - val_mse: 8450696.0000\n",
      "Epoch 379/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1778331.3750 - mse: 1778331.3750\n",
      "Epoch 379: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1777592.5000 - mse: 1777592.5000 - val_loss: 9464812.0000 - val_mse: 9464812.0000\n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2158353.2500 - mse: 2158353.2500\n",
      "Epoch 380: loss did not improve from 1498080.12500\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2158353.2500 - mse: 2158353.2500 - val_loss: 6578475.0000 - val_mse: 6578475.0000\n",
      "Epoch 381/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1376942.6250 - mse: 1376942.6250\n",
      "Epoch 381: loss improved from 1498080.12500 to 1411930.50000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1411930.5000 - mse: 1411930.5000 - val_loss: 6622429.0000 - val_mse: 6622429.0000\n",
      "Epoch 382/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1691437.1250 - mse: 1691437.1250\n",
      "Epoch 382: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1689568.7500 - mse: 1689568.7500 - val_loss: 7518489.0000 - val_mse: 7518489.0000\n",
      "Epoch 383/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1611407.6250 - mse: 1611407.6250\n",
      "Epoch 383: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1616705.7500 - mse: 1616705.7500 - val_loss: 7666169.0000 - val_mse: 7666169.0000\n",
      "Epoch 384/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1830697.2500 - mse: 1830697.2500\n",
      "Epoch 384: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1810424.0000 - mse: 1810424.0000 - val_loss: 8027465.0000 - val_mse: 8027465.0000\n",
      "Epoch 385/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1792554.2500 - mse: 1792554.2500\n",
      "Epoch 385: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1812297.6250 - mse: 1812297.6250 - val_loss: 7000936.0000 - val_mse: 7000936.0000\n",
      "Epoch 386/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1704902.5000 - mse: 1704902.5000\n",
      "Epoch 386: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1709827.6250 - mse: 1709827.6250 - val_loss: 7170698.5000 - val_mse: 7170698.5000\n",
      "Epoch 387/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1784534.0000 - mse: 1784534.0000\n",
      "Epoch 387: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1789092.1250 - mse: 1789092.1250 - val_loss: 7224773.0000 - val_mse: 7224773.0000\n",
      "Epoch 388/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1898569.6250 - mse: 1898569.6250\n",
      "Epoch 388: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1901117.8750 - mse: 1901117.8750 - val_loss: 7266141.5000 - val_mse: 7266141.5000\n",
      "Epoch 389/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1967821.5000 - mse: 1967821.5000\n",
      "Epoch 389: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1964480.1250 - mse: 1964480.1250 - val_loss: 7189311.0000 - val_mse: 7189311.0000\n",
      "Epoch 390/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1857880.7500 - mse: 1857880.7500\n",
      "Epoch 390: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1850268.6250 - mse: 1850268.6250 - val_loss: 7564191.0000 - val_mse: 7564191.0000\n",
      "Epoch 391/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1718310.2500 - mse: 1718310.2500\n",
      "Epoch 391: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1725980.7500 - mse: 1725980.7500 - val_loss: 7073184.0000 - val_mse: 7073184.0000\n",
      "Epoch 392/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 2139155.2500 - mse: 2139155.2500\n",
      "Epoch 392: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2169936.2500 - mse: 2169936.2500 - val_loss: 7165028.0000 - val_mse: 7165028.0000\n",
      "Epoch 393/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1647271.6250 - mse: 1647271.6250\n",
      "Epoch 393: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1650856.1250 - mse: 1650856.1250 - val_loss: 8065829.0000 - val_mse: 8065829.0000\n",
      "Epoch 394/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1614742.1250 - mse: 1614742.1250\n",
      "Epoch 394: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1620353.1250 - mse: 1620353.1250 - val_loss: 6882914.0000 - val_mse: 6882914.0000\n",
      "Epoch 395/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1643026.7500 - mse: 1643026.7500\n",
      "Epoch 395: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1638828.5000 - mse: 1638828.5000 - val_loss: 7336358.0000 - val_mse: 7336358.0000\n",
      "Epoch 396/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1675612.0000 - mse: 1675612.0000\n",
      "Epoch 396: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1667168.7500 - mse: 1667168.7500 - val_loss: 7233165.5000 - val_mse: 7233165.5000\n",
      "Epoch 397/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1701818.7500 - mse: 1701818.7500\n",
      "Epoch 397: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1703645.8750 - mse: 1703645.8750 - val_loss: 6857849.5000 - val_mse: 6857849.5000\n",
      "Epoch 398/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1576723.7500 - mse: 1576723.7500\n",
      "Epoch 398: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1581766.2500 - mse: 1581766.2500 - val_loss: 7962786.0000 - val_mse: 7962786.0000\n",
      "Epoch 399/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1634047.8750 - mse: 1634047.8750\n",
      "Epoch 399: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1626823.5000 - mse: 1626823.5000 - val_loss: 8215554.0000 - val_mse: 8215554.0000\n",
      "Epoch 400/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1830141.8750 - mse: 1830141.8750\n",
      "Epoch 400: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1809856.6250 - mse: 1809856.6250 - val_loss: 7091997.0000 - val_mse: 7091997.0000\n",
      "Epoch 401/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1727403.8750 - mse: 1727403.8750\n",
      "Epoch 401: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1722660.0000 - mse: 1722660.0000 - val_loss: 7761881.5000 - val_mse: 7761881.5000\n",
      "Epoch 402/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1858664.6250 - mse: 1858664.6250\n",
      "Epoch 402: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1851291.8750 - mse: 1851291.8750 - val_loss: 6747627.0000 - val_mse: 6747627.0000\n",
      "Epoch 403/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1685303.5000 - mse: 1685303.5000\n",
      "Epoch 403: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1674969.2500 - mse: 1674969.2500 - val_loss: 6843502.0000 - val_mse: 6843502.0000\n",
      "Epoch 404/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1601827.2500 - mse: 1601827.2500\n",
      "Epoch 404: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1597772.0000 - mse: 1597772.0000 - val_loss: 6944977.0000 - val_mse: 6944977.0000\n",
      "Epoch 405/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1696007.8750 - mse: 1696007.8750\n",
      "Epoch 405: loss did not improve from 1411930.50000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1668625.7500 - mse: 1668625.7500 - val_loss: 8159050.5000 - val_mse: 8159050.5000\n",
      "Epoch 406/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1238290.1250 - mse: 1238290.1250\n",
      "Epoch 406: loss improved from 1411930.50000 to 1256296.75000, saving model to lstm_model_checkpoint_try4.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1256296.7500 - mse: 1256296.7500 - val_loss: 7832235.0000 - val_mse: 7832235.0000\n",
      "Epoch 407/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1446272.8750 - mse: 1446272.8750\n",
      "Epoch 407: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1442208.6250 - mse: 1442208.6250 - val_loss: 8230975.5000 - val_mse: 8230975.5000\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1415352.3750 - mse: 1415352.3750\n",
      "Epoch 408: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1415352.3750 - mse: 1415352.3750 - val_loss: 6690648.0000 - val_mse: 6690648.0000\n",
      "Epoch 409/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1886833.5000 - mse: 1886833.5000\n",
      "Epoch 409: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1868716.1250 - mse: 1868716.1250 - val_loss: 8490155.0000 - val_mse: 8490155.0000\n",
      "Epoch 410/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1516873.1250 - mse: 1516873.1250\n",
      "Epoch 410: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1520469.7500 - mse: 1520469.7500 - val_loss: 8059003.0000 - val_mse: 8059003.0000\n",
      "Epoch 411/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1568415.3750 - mse: 1568415.3750\n",
      "Epoch 411: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1553357.1250 - mse: 1553357.1250 - val_loss: 8791307.0000 - val_mse: 8791307.0000\n",
      "Epoch 412/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1580471.0000 - mse: 1580471.0000\n",
      "Epoch 412: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1576150.0000 - mse: 1576150.0000 - val_loss: 8420932.0000 - val_mse: 8420932.0000\n",
      "Epoch 413/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1766999.3750 - mse: 1766999.3750\n",
      "Epoch 413: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1754088.1250 - mse: 1754088.1250 - val_loss: 9370164.0000 - val_mse: 9370164.0000\n",
      "Epoch 414/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1758882.2500 - mse: 1758882.2500\n",
      "Epoch 414: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1756016.3750 - mse: 1756016.3750 - val_loss: 7211576.5000 - val_mse: 7211576.5000\n",
      "Epoch 415/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1649120.0000 - mse: 1649120.0000\n",
      "Epoch 415: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1651762.8750 - mse: 1651762.8750 - val_loss: 7941042.0000 - val_mse: 7941042.0000\n",
      "Epoch 416/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1588987.8750 - mse: 1588987.8750\n",
      "Epoch 416: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1594433.8750 - mse: 1594433.8750 - val_loss: 9699636.0000 - val_mse: 9699636.0000\n",
      "Epoch 417/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1932765.1250 - mse: 1932765.1250\n",
      "Epoch 417: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1923786.3750 - mse: 1923786.3750 - val_loss: 7866543.0000 - val_mse: 7866543.0000\n",
      "Epoch 418/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1525571.7500 - mse: 1525571.7500\n",
      "Epoch 418: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1528688.5000 - mse: 1528688.5000 - val_loss: 8195065.0000 - val_mse: 8195065.0000\n",
      "Epoch 419/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1438748.7500 - mse: 1438748.7500\n",
      "Epoch 419: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1441281.2500 - mse: 1441281.2500 - val_loss: 7102268.0000 - val_mse: 7102268.0000\n",
      "Epoch 420/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1317839.8750 - mse: 1317839.8750\n",
      "Epoch 420: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1325720.1250 - mse: 1325720.1250 - val_loss: 7261817.0000 - val_mse: 7261817.0000\n",
      "Epoch 421/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1531712.1250 - mse: 1531712.1250\n",
      "Epoch 421: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1522228.7500 - mse: 1522228.7500 - val_loss: 7656356.0000 - val_mse: 7656356.0000\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1474959.8750 - mse: 1474959.8750\n",
      "Epoch 422: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1474959.8750 - mse: 1474959.8750 - val_loss: 8082833.0000 - val_mse: 8082833.0000\n",
      "Epoch 423/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1509124.0000 - mse: 1509124.0000\n",
      "Epoch 423: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1519801.2500 - mse: 1519801.2500 - val_loss: 7297297.5000 - val_mse: 7297297.5000\n",
      "Epoch 424/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1449345.6250 - mse: 1449345.6250\n",
      "Epoch 424: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1464683.0000 - mse: 1464683.0000 - val_loss: 8181562.0000 - val_mse: 8181562.0000\n",
      "Epoch 425/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1605932.3750 - mse: 1605932.3750\n",
      "Epoch 425: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1606101.5000 - mse: 1606101.5000 - val_loss: 7699558.5000 - val_mse: 7699558.5000\n",
      "Epoch 426/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1624411.2500 - mse: 1624411.2500\n",
      "Epoch 426: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1651828.6250 - mse: 1651828.6250 - val_loss: 9195607.0000 - val_mse: 9195607.0000\n",
      "Epoch 427/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1679373.5000 - mse: 1679373.5000\n",
      "Epoch 427: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1670855.5000 - mse: 1670855.5000 - val_loss: 8667804.0000 - val_mse: 8667804.0000\n",
      "Epoch 428/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1640023.3750 - mse: 1640023.3750\n",
      "Epoch 428: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1617655.2500 - mse: 1617655.2500 - val_loss: 9066390.0000 - val_mse: 9066390.0000\n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1740551.6250 - mse: 1740551.6250\n",
      "Epoch 429: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1740551.6250 - mse: 1740551.6250 - val_loss: 7537205.0000 - val_mse: 7537205.0000\n",
      "Epoch 430/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1668751.8750 - mse: 1668751.8750\n",
      "Epoch 430: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1681461.8750 - mse: 1681461.8750 - val_loss: 8021642.5000 - val_mse: 8021642.5000\n",
      "Epoch 431/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1330014.0000 - mse: 1330014.0000\n",
      "Epoch 431: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1339597.6250 - mse: 1339597.6250 - val_loss: 9892040.0000 - val_mse: 9892040.0000\n",
      "Epoch 432/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2088179.8750 - mse: 2088179.8750\n",
      "Epoch 432: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2062769.7500 - mse: 2062769.7500 - val_loss: 9948376.0000 - val_mse: 9948376.0000\n",
      "Epoch 433/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1869824.3750 - mse: 1869824.3750\n",
      "Epoch 433: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1858717.6250 - mse: 1858717.6250 - val_loss: 11842984.0000 - val_mse: 11842984.0000\n",
      "Epoch 434/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1765526.6250 - mse: 1765526.6250\n",
      "Epoch 434: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1784870.3750 - mse: 1784870.3750 - val_loss: 10929748.0000 - val_mse: 10929748.0000\n",
      "Epoch 435/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1783107.6250 - mse: 1783107.6250\n",
      "Epoch 435: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1796295.3750 - mse: 1796295.3750 - val_loss: 10947531.0000 - val_mse: 10947531.0000\n",
      "Epoch 436/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1629071.1250 - mse: 1629071.1250\n",
      "Epoch 436: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1612715.3750 - mse: 1612715.3750 - val_loss: 10016092.0000 - val_mse: 10016092.0000\n",
      "Epoch 437/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1770417.8750 - mse: 1770417.8750\n",
      "Epoch 437: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1756885.7500 - mse: 1756885.7500 - val_loss: 10400677.0000 - val_mse: 10400677.0000\n",
      "Epoch 438/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1791238.6250 - mse: 1791238.6250\n",
      "Epoch 438: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1783955.8750 - mse: 1783955.8750 - val_loss: 9474028.0000 - val_mse: 9474028.0000\n",
      "Epoch 439/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1953179.5000 - mse: 1953179.5000\n",
      "Epoch 439: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1954864.5000 - mse: 1954864.5000 - val_loss: 9483116.0000 - val_mse: 9483116.0000\n",
      "Epoch 440/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1796886.3750 - mse: 1796886.3750\n",
      "Epoch 440: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1801519.8750 - mse: 1801519.8750 - val_loss: 9022493.0000 - val_mse: 9022493.0000\n",
      "Epoch 441/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1721625.6250 - mse: 1721625.6250\n",
      "Epoch 441: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1723931.8750 - mse: 1723931.8750 - val_loss: 9913005.0000 - val_mse: 9913005.0000\n",
      "Epoch 442/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1773759.0000 - mse: 1773759.0000\n",
      "Epoch 442: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1781996.5000 - mse: 1781996.5000 - val_loss: 10912265.0000 - val_mse: 10912265.0000\n",
      "Epoch 443/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1601493.3750 - mse: 1601493.3750\n",
      "Epoch 443: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1641939.3750 - mse: 1641939.3750 - val_loss: 12838464.0000 - val_mse: 12838464.0000\n",
      "Epoch 444/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1519269.1250 - mse: 1519269.1250\n",
      "Epoch 444: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1510812.7500 - mse: 1510812.7500 - val_loss: 12369807.0000 - val_mse: 12369807.0000\n",
      "Epoch 445/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1536385.5000 - mse: 1536385.5000\n",
      "Epoch 445: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1542637.6250 - mse: 1542637.6250 - val_loss: 13448705.0000 - val_mse: 13448705.0000\n",
      "Epoch 446/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1667864.8750 - mse: 1667864.8750\n",
      "Epoch 446: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1679050.2500 - mse: 1679050.2500 - val_loss: 12697419.0000 - val_mse: 12697419.0000\n",
      "Epoch 447/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1641733.6250 - mse: 1641733.6250\n",
      "Epoch 447: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1638194.5000 - mse: 1638194.5000 - val_loss: 13270238.0000 - val_mse: 13270238.0000\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1581194.3750 - mse: 1581194.3750\n",
      "Epoch 448: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1581194.3750 - mse: 1581194.3750 - val_loss: 12367620.0000 - val_mse: 12367620.0000\n",
      "Epoch 449/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1608184.3750 - mse: 1608184.3750\n",
      "Epoch 449: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1607958.8750 - mse: 1607958.8750 - val_loss: 12199047.0000 - val_mse: 12199047.0000\n",
      "Epoch 450/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1728685.1250 - mse: 1728685.1250\n",
      "Epoch 450: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1731677.1250 - mse: 1731677.1250 - val_loss: 12830786.0000 - val_mse: 12830786.0000\n",
      "Epoch 451/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1816319.3750 - mse: 1816319.3750\n",
      "Epoch 451: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1844917.8750 - mse: 1844917.8750 - val_loss: 12354867.0000 - val_mse: 12354867.0000\n",
      "Epoch 452/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1760847.6250 - mse: 1760847.6250\n",
      "Epoch 452: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1772925.7500 - mse: 1772925.7500 - val_loss: 11066502.0000 - val_mse: 11066502.0000\n",
      "Epoch 453/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1530045.2500 - mse: 1530045.2500\n",
      "Epoch 453: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1518841.1250 - mse: 1518841.1250 - val_loss: 13129021.0000 - val_mse: 13129021.0000\n",
      "Epoch 454/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1804263.8750 - mse: 1804263.8750\n",
      "Epoch 454: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1795921.8750 - mse: 1795921.8750 - val_loss: 13057226.0000 - val_mse: 13057226.0000\n",
      "Epoch 455/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1722363.8750 - mse: 1722363.8750\n",
      "Epoch 455: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1653810.2500 - mse: 1653810.2500 - val_loss: 12287606.0000 - val_mse: 12287606.0000\n",
      "Epoch 456/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1322197.7500 - mse: 1322197.7500\n",
      "Epoch 456: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1334141.2500 - mse: 1334141.2500 - val_loss: 11951549.0000 - val_mse: 11951549.0000\n",
      "Epoch 457/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1590124.5000 - mse: 1590124.5000\n",
      "Epoch 457: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1580333.5000 - mse: 1580333.5000 - val_loss: 11801276.0000 - val_mse: 11801276.0000\n",
      "Epoch 458/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1562539.5000 - mse: 1562539.5000\n",
      "Epoch 458: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1551968.5000 - mse: 1551968.5000 - val_loss: 12744536.0000 - val_mse: 12744536.0000\n",
      "Epoch 459/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1688780.2500 - mse: 1688780.2500\n",
      "Epoch 459: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1673350.8750 - mse: 1673350.8750 - val_loss: 11771974.0000 - val_mse: 11771974.0000\n",
      "Epoch 460/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1636185.3750 - mse: 1636185.3750\n",
      "Epoch 460: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1635519.3750 - mse: 1635519.3750 - val_loss: 11786202.0000 - val_mse: 11786202.0000\n",
      "Epoch 461/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1539355.8750 - mse: 1539355.8750\n",
      "Epoch 461: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1544509.2500 - mse: 1544509.2500 - val_loss: 10678426.0000 - val_mse: 10678426.0000\n",
      "Epoch 462/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1784105.3750 - mse: 1784105.3750\n",
      "Epoch 462: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1785018.3750 - mse: 1785018.3750 - val_loss: 11148817.0000 - val_mse: 11148817.0000\n",
      "Epoch 463/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1739367.5000 - mse: 1739367.5000\n",
      "Epoch 463: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1739568.7500 - mse: 1739568.7500 - val_loss: 9954017.0000 - val_mse: 9954017.0000\n",
      "Epoch 464/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1862033.3750 - mse: 1862033.3750\n",
      "Epoch 464: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1844449.8750 - mse: 1844449.8750 - val_loss: 12167806.0000 - val_mse: 12167806.0000\n",
      "Epoch 465/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1857883.8750 - mse: 1857883.8750\n",
      "Epoch 465: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1843694.8750 - mse: 1843694.8750 - val_loss: 12911742.0000 - val_mse: 12911742.0000\n",
      "Epoch 466/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1553167.1250 - mse: 1553167.1250\n",
      "Epoch 466: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1578081.2500 - mse: 1578081.2500 - val_loss: 11379230.0000 - val_mse: 11379230.0000\n",
      "Epoch 467/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1837303.1250 - mse: 1837303.1250\n",
      "Epoch 467: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1850501.0000 - mse: 1850501.0000 - val_loss: 11168742.0000 - val_mse: 11168742.0000\n",
      "Epoch 468/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1467304.0000 - mse: 1467304.0000\n",
      "Epoch 468: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1441083.3750 - mse: 1441083.3750 - val_loss: 12436442.0000 - val_mse: 12436442.0000\n",
      "Epoch 469/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1488013.7500 - mse: 1488013.7500\n",
      "Epoch 469: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1439770.2500 - mse: 1439770.2500 - val_loss: 10667713.0000 - val_mse: 10667713.0000\n",
      "Epoch 470/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1492130.2500 - mse: 1492130.2500\n",
      "Epoch 470: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1488606.3750 - mse: 1488606.3750 - val_loss: 10836024.0000 - val_mse: 10836024.0000\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1570237.0000 - mse: 1570237.0000\n",
      "Epoch 471: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1570237.0000 - mse: 1570237.0000 - val_loss: 10920742.0000 - val_mse: 10920742.0000\n",
      "Epoch 472/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1582150.6250 - mse: 1582150.6250\n",
      "Epoch 472: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1580480.6250 - mse: 1580480.6250 - val_loss: 9902474.0000 - val_mse: 9902474.0000\n",
      "Epoch 473/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1656592.8750 - mse: 1656592.8750\n",
      "Epoch 473: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1654167.2500 - mse: 1654167.2500 - val_loss: 12127746.0000 - val_mse: 12127746.0000\n",
      "Epoch 474/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1534248.3750 - mse: 1534248.3750\n",
      "Epoch 474: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1525437.0000 - mse: 1525437.0000 - val_loss: 12151703.0000 - val_mse: 12151703.0000\n",
      "Epoch 475/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1692809.3750 - mse: 1692809.3750\n",
      "Epoch 475: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1701947.5000 - mse: 1701947.5000 - val_loss: 12105730.0000 - val_mse: 12105730.0000\n",
      "Epoch 476/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1866165.2500 - mse: 1866165.2500\n",
      "Epoch 476: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1858328.7500 - mse: 1858328.7500 - val_loss: 11071242.0000 - val_mse: 11071242.0000\n",
      "Epoch 477/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1744176.5000 - mse: 1744176.5000\n",
      "Epoch 477: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1757816.0000 - mse: 1757816.0000 - val_loss: 10046499.0000 - val_mse: 10046499.0000\n",
      "Epoch 478/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1541937.8750 - mse: 1541937.8750\n",
      "Epoch 478: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1559093.2500 - mse: 1559093.2500 - val_loss: 10922922.0000 - val_mse: 10922922.0000\n",
      "Epoch 479/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1705157.3750 - mse: 1705157.3750\n",
      "Epoch 479: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1678073.2500 - mse: 1678073.2500 - val_loss: 12430958.0000 - val_mse: 12430958.0000\n",
      "Epoch 480/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1570593.5000 - mse: 1570593.5000\n",
      "Epoch 480: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1561891.6250 - mse: 1561891.6250 - val_loss: 13635466.0000 - val_mse: 13635466.0000\n",
      "Epoch 481/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1355434.2500 - mse: 1355434.2500\n",
      "Epoch 481: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1341622.7500 - mse: 1341622.7500 - val_loss: 11304062.0000 - val_mse: 11304062.0000\n",
      "Epoch 482/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1481406.5000 - mse: 1481406.5000\n",
      "Epoch 482: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1496193.6250 - mse: 1496193.6250 - val_loss: 10153619.0000 - val_mse: 10153619.0000\n",
      "Epoch 483/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1419213.8750 - mse: 1419213.8750\n",
      "Epoch 483: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1438785.7500 - mse: 1438785.7500 - val_loss: 9994984.0000 - val_mse: 9994984.0000\n",
      "Epoch 484/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1538907.2500 - mse: 1538907.2500\n",
      "Epoch 484: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1526452.0000 - mse: 1526452.0000 - val_loss: 11091818.0000 - val_mse: 11091818.0000\n",
      "Epoch 485/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1461344.0000 - mse: 1461344.0000\n",
      "Epoch 485: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1472182.3750 - mse: 1472182.3750 - val_loss: 11365387.0000 - val_mse: 11365387.0000\n",
      "Epoch 486/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1452933.2500 - mse: 1452933.2500\n",
      "Epoch 486: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1491145.1250 - mse: 1491145.1250 - val_loss: 11308450.0000 - val_mse: 11308450.0000\n",
      "Epoch 487/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1520570.7500 - mse: 1520570.7500\n",
      "Epoch 487: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1534423.3750 - mse: 1534423.3750 - val_loss: 10970518.0000 - val_mse: 10970518.0000\n",
      "Epoch 488/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1652393.7500 - mse: 1652393.7500\n",
      "Epoch 488: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1653173.6250 - mse: 1653173.6250 - val_loss: 10203223.0000 - val_mse: 10203223.0000\n",
      "Epoch 489/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1856053.8750 - mse: 1856053.8750\n",
      "Epoch 489: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1867489.2500 - mse: 1867489.2500 - val_loss: 9661590.0000 - val_mse: 9661590.0000\n",
      "Epoch 490/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1677080.1250 - mse: 1677080.1250\n",
      "Epoch 490: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1674727.8750 - mse: 1674727.8750 - val_loss: 10142945.0000 - val_mse: 10142945.0000\n",
      "Epoch 491/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1644497.5000 - mse: 1644497.5000\n",
      "Epoch 491: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1635526.7500 - mse: 1635526.7500 - val_loss: 10427054.0000 - val_mse: 10427054.0000\n",
      "Epoch 492/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1707192.6250 - mse: 1707192.6250\n",
      "Epoch 492: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1693198.8750 - mse: 1693198.8750 - val_loss: 10896060.0000 - val_mse: 10896060.0000\n",
      "Epoch 493/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1426194.6250 - mse: 1426194.6250\n",
      "Epoch 493: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1393108.0000 - mse: 1393108.0000 - val_loss: 12135452.0000 - val_mse: 12135452.0000\n",
      "Epoch 494/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1453219.1250 - mse: 1453219.1250\n",
      "Epoch 494: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1467703.8750 - mse: 1467703.8750 - val_loss: 11911487.0000 - val_mse: 11911487.0000\n",
      "Epoch 495/1000\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1438333.2500 - mse: 1438333.2500\n",
      "Epoch 495: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1443685.8750 - mse: 1443685.8750 - val_loss: 10760438.0000 - val_mse: 10760438.0000\n",
      "Epoch 496/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1559755.5000 - mse: 1559755.5000\n",
      "Epoch 496: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1551521.6250 - mse: 1551521.6250 - val_loss: 11426542.0000 - val_mse: 11426542.0000\n",
      "Epoch 497/1000\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1600673.7500 - mse: 1600673.7500\n",
      "Epoch 497: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1605469.0000 - mse: 1605469.0000 - val_loss: 9705355.0000 - val_mse: 9705355.0000\n",
      "Epoch 498/1000\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1500756.7500 - mse: 1500756.7500\n",
      "Epoch 498: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1511595.6250 - mse: 1511595.6250 - val_loss: 9932227.0000 - val_mse: 9932227.0000\n",
      "Epoch 499/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1522628.1250 - mse: 1522628.1250\n",
      "Epoch 499: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1517150.8750 - mse: 1517150.8750 - val_loss: 11388684.0000 - val_mse: 11388684.0000\n",
      "Epoch 500/1000\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1651492.3750 - mse: 1651492.3750\n",
      "Epoch 500: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1646193.7500 - mse: 1646193.7500 - val_loss: 10441861.0000 - val_mse: 10441861.0000\n",
      "Epoch 501/1000\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1712120.1250 - mse: 1712120.1250\n",
      "Epoch 501: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1683886.2500 - mse: 1683886.2500 - val_loss: 11013907.0000 - val_mse: 11013907.0000\n",
      "Epoch 502/1000\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1703722.0000 - mse: 1703722.0000\n",
      "Epoch 502: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1682758.7500 - mse: 1682758.7500 - val_loss: 11450022.0000 - val_mse: 11450022.0000\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1559363.2500 - mse: 1559363.2500\n",
      "Epoch 503: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1559363.2500 - mse: 1559363.2500 - val_loss: 9622950.0000 - val_mse: 9622950.0000\n",
      "Epoch 504/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2098354.0000 - mse: 2098354.0000\n",
      "Epoch 504: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2101595.2500 - mse: 2101595.2500 - val_loss: 12348922.0000 - val_mse: 12348922.0000\n",
      "Epoch 505/1000\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1586780.5000 - mse: 1586780.5000\n",
      "Epoch 505: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1559020.0000 - mse: 1559020.0000 - val_loss: 10133004.0000 - val_mse: 10133004.0000\n",
      "Epoch 506/1000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1371449.8750 - mse: 1371449.8750\n",
      "Epoch 506: loss did not improve from 1256296.75000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1387268.7500 - mse: 1387268.7500 - val_loss: 10193109.0000 - val_mse: 10193109.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the Model(val)\n",
    "EVALUATION_INTERVAL = 100\n",
    "EPOCHS = 1000\n",
    "\n",
    "history=simple_lstm_model.fit(train_univariate , epochs=EPOCHS,validation_data=val_univariate,steps_per_epoch=EVALUATION_INTERVAL,validation_steps=1,verbose=1,callbacks=[es_callback, modelckpt_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kerastuner_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hp.Int('input_unit',min_value=32,max_value=512,step=32),return_sequences=True, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    for i in range(hp.Int('n_layers', 1, 4)):\n",
    "        model.add(LSTM(hp.Int(f'lstm_{i}_units',min_value=32,max_value=512,step=32),return_sequences=True))\n",
    "    model.add(LSTM(hp.Int('layer_2_neurons',min_value=32,max_value=512,step=32)))\n",
    "    model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n",
    "    model.add(Dense(Y_train.shape[1], activation=hp.Choice('dense_activation',values=['relu', 'sigmoid'],default='relu')))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsm.visualize_loss(history, \"Training & vaildation Loss\",'C:/Users/USER/Desktop/진행중/FEMS/moorim/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>yhat</th>\n",
       "      <th>y</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3577.253662</td>\n",
       "      <td>5846.4</td>\n",
       "      <td>2022-06-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3594.415039</td>\n",
       "      <td>5812.8</td>\n",
       "      <td>2022-06-30 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3608.278320</td>\n",
       "      <td>5745.6</td>\n",
       "      <td>2022-06-30 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3625.884033</td>\n",
       "      <td>5712.0</td>\n",
       "      <td>2022-06-30 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3645.950195</td>\n",
       "      <td>5745.6</td>\n",
       "      <td>2022-06-30 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>3455.373047</td>\n",
       "      <td>5796.0</td>\n",
       "      <td>2022-06-30 20:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>3445.464844</td>\n",
       "      <td>5812.8</td>\n",
       "      <td>2022-06-30 20:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>3432.260742</td>\n",
       "      <td>5661.6</td>\n",
       "      <td>2022-06-30 20:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>3418.930176</td>\n",
       "      <td>5796.0</td>\n",
       "      <td>2022-06-30 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>3403.576904</td>\n",
       "      <td>5846.4</td>\n",
       "      <td>2022-06-30 21:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index         yhat       y                time\n",
       "0       0  3577.253662  5846.4 2022-06-30 00:00:00\n",
       "1       1  3594.415039  5812.8 2022-06-30 00:15:00\n",
       "2       2  3608.278320  5745.6 2022-06-30 00:30:00\n",
       "3       3  3625.884033  5712.0 2022-06-30 00:45:00\n",
       "4       4  3645.950195  5745.6 2022-06-30 01:00:00\n",
       "..    ...          ...     ...                 ...\n",
       "81     81  3455.373047  5796.0 2022-06-30 20:15:00\n",
       "82     82  3445.464844  5812.8 2022-06-30 20:30:00\n",
       "83     83  3432.260742  5661.6 2022-06-30 20:45:00\n",
       "84     84  3418.930176  5796.0 2022-06-30 21:00:00\n",
       "85     85  3403.576904  5846.4 2022-06-30 21:15:00\n",
       "\n",
       "[86 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = simple_lstm_model.predict(test_x)\n",
    "prediction=pd.DataFrame(yhat)\n",
    "prediction.columns=['yhat']\n",
    "# prediction.index=df_test[4:].index   # index 설정방법\n",
    "df_test=df_test.reset_index()\n",
    "prediction=prediction.reset_index()\n",
    "prediction['y']=df_test['직전 15분 사용전력']\n",
    "prediction['time']=df_test['기준시각']\n",
    "prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'기준시각'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '기준시각'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\Documents\\GitHub\\Time_Series_models\\Demand_predict\\Moorim_demand_predict.ipynb 셀 36\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/GitHub/Time_Series_models/Demand_predict/Moorim_demand_predict.ipynb#ch0000022?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m,\u001b[39m20\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/GitHub/Time_Series_models/Demand_predict/Moorim_demand_predict.ipynb#ch0000022?line=1'>2</a>\u001b[0m kws \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(marker\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/GitHub/Time_Series_models/Demand_predict/Moorim_demand_predict.ipynb#ch0000022?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(train[\u001b[39m'\u001b[39;49m\u001b[39m기준시각\u001b[39;49m\u001b[39m'\u001b[39;49m],train[\u001b[39m'\u001b[39m\u001b[39m직전 15분 사용전력\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkws)   \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/GitHub/Time_Series_models/Demand_predict/Moorim_demand_predict.ipynb#ch0000022?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(test[\u001b[39m'\u001b[39m\u001b[39m기준시각\u001b[39m\u001b[39m'\u001b[39m],test[\u001b[39m'\u001b[39m\u001b[39m직전 15분 사용전력\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkws)   \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/GitHub/Time_Series_models/Demand_predict/Moorim_demand_predict.ipynb#ch0000022?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(prediction[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m],prediction[\u001b[39m'\u001b[39m\u001b[39myhat\u001b[39m\u001b[39m'\u001b[39m],label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredicted\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkws)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '기준시각'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "kws = dict(marker='o')\n",
    "plt.plot(train['기준시각'],train['직전 15분 사용전력'], label='Train', **kws)   \n",
    "plt.plot(test['기준시각'],test['직전 15분 사용전력'], label='Test', **kws)   \n",
    "plt.plot(prediction['time'],prediction['yhat'],label='predicted', **kws)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d5c1156327dacead463cc502c55ebae8ce9c8c01979cf154173ff808e75bf55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
